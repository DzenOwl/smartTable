{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grokaem DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y7gXTQIL566"
      },
      "source": [
        "Одна точка входа"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZxnZU61JYM3",
        "outputId": "29c04850-ddb8-4110-9bfa-6bd16abb97fb"
      },
      "source": [
        "def neural_network_1(input, weight):\n",
        "    pred = input * weight\n",
        "    return pred\n",
        "\n",
        "weight = 0.1\n",
        "toes_num = [8.5, 9.5, 10, 9]\n",
        "input = toes_num[0]\n",
        "pred = neural_network_1(input, weight)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8500000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRPJnkUTL_H2"
      },
      "source": [
        "Несколько точек входа, взвешенная сумма (скалярное произведение)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsM9QnwQKQPZ"
      },
      "source": [
        "def w_sum(a, b):\n",
        "    assert(len(a) == len(b))\n",
        "    output = 0\n",
        "    for i in range(len(a)):\n",
        "        output += (a[i] * b[i])\n",
        "    return output\n",
        "\n",
        "def neural_network_2(input, weights):\n",
        "    pred = w_sum(input, weights)\n",
        "    return pred\n",
        "\n",
        "weights = [0.1, 0.2, 0]\n",
        "\n",
        "toes = [8.5, 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "nfans = [1.2, 1.3, 0.5, 1.0]\n",
        "input = [toes[0], wlrec[0], nfans[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhvBbj_bKRFB",
        "outputId": "c093f3db-9b51-4c0d-ab56-3af8ca00e7d1"
      },
      "source": [
        "pred = neural_network_2(input, weights)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9800000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DinMrR3HNfb8",
        "outputId": "4c5f5a43-2daf-4716-d7cf-439b132d28c2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def neural_network_np(input, weights):\n",
        "    pred = input.dot(weights) # dot product = scalar multiply\n",
        "    return pred\n",
        "\n",
        "weights = np.array([0.1, 0.2, 0])\n",
        "\n",
        "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
        "wlrec = np.array([0.65, 0.8, 0.8, 0.9])\n",
        "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
        "input = np.array([toes[0], wlrec[0], nfans[0]])\n",
        "\n",
        "pred = neural_network_np(input,weights)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9800000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0TJuElDKRHR",
        "outputId": "91bd6e3c-61ea-4c94-f6a5-b9e8b803ceef"
      },
      "source": [
        "def ele_mul(number,vector):\n",
        "    output = [0,0,0]\n",
        "    assert(len(output) == len(vector))\n",
        "    for i in range(len(vector)):\n",
        "        output[i] = number * vector[i]\n",
        "    return output\n",
        "\n",
        "def neural_network_3(input, weights):\n",
        "    pred = ele_mul(input, weights)\n",
        "    return pred\n",
        "\n",
        "weights = [0.3, 0.2, 0.9]\n",
        "    \n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "input = wlrec[0]\n",
        "pred = neural_network_3(input, weights)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.195, 0.13, 0.5850000000000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOBNT9VKKRJ1",
        "outputId": "b7b99843-3c32-4844-a7a0-1d60a2c8d18c"
      },
      "source": [
        "def w_sum(a, b):\n",
        "    assert(len(a) == len(b))\n",
        "    output = 0\n",
        "    for i in range(len(a)):\n",
        "        output += (a[i] * b[i])\n",
        "    return output\n",
        "\n",
        "def vect_mat_mul(vect,matrix):\n",
        "    assert(len(vect) == len(matrix))\n",
        "    output = [0, 0, 0]\n",
        "    for i in range(len(vect)):\n",
        "        output[i] = w_sum(vect,matrix[i])\n",
        "    return output\n",
        "\n",
        "def neural_network_4(input, weights):\n",
        "    pred = vect_mat_mul(input, weights)\n",
        "    return pred\n",
        "\n",
        "weights = [ \n",
        "    [0.1, 0.1, -0.3],\n",
        "    [0.1, 0.2,0.0],\n",
        "    [0.0, 1.3, 0.1]\n",
        "]\n",
        "\n",
        "toes = [8.5, 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65,0.8, 0.8, 0.9]\n",
        "nfans = [1.2, 1.3, 0.5, 1.0]\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "pred = neural_network_4(input,weights)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.555, 0.9800000000000001, 0.9650000000000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a70kL5NYKRMf",
        "outputId": "7759522b-fd8e-43cd-fc69-b1a95d0624f6"
      },
      "source": [
        "ih_wgt = [ \n",
        "[0.1, 0.2, -0.1], \n",
        "[-0.1,0.1, 0.9], \n",
        "[0.1, 0.4, 0.1] \n",
        "] \n",
        "hp_wgt = [ \n",
        "[0.3, 1.1, -0.3], \n",
        "[0.1, 0.2, 0.0], \n",
        "[0.0, 1.3, 0.1] \n",
        "] \n",
        "weights = [ih_wgt, hp_wgt]\n",
        "\n",
        "def neural_network_5(input, weights):\n",
        "    hid = vect_mat_mul(input,weights[0])\n",
        "    pred = vect_mat_mul(hid,weights[1])\n",
        "    return pred\n",
        "\n",
        "toes = [8.5, 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65,0.8, 0.8, 0.9]\n",
        "nfans = [1.2, 1.3, 0.5, 1.0]\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "pred = neural_network_5(input, weights)\n",
        "print(pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.21350000000000002, 0.14500000000000002, 0.5065]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTw2oYMPKRPH",
        "outputId": "ea753639-d41c-4e63-cabf-20f38da09375"
      },
      "source": [
        "ih_wgt = np.array([\n",
        "[0.1, 0.2, -0.1], \n",
        "[-0.1,0.1, 0.9], \n",
        "[0.1, 0.4, 0.1]])\n",
        "ih_wgt = ih_wgt.T\n",
        "\n",
        "hp_wgt = np.array([\n",
        "[0.3, 1.1, -0.3], \n",
        "[0.1, 0.2, 0.0], \n",
        "[0.0, 1.3, 0.1] ])\n",
        "hp_wgt = hp_wgt.T\n",
        "\n",
        "weights = [ih_wgt, hp_wgt]\n",
        "\n",
        "def neural_network_6(input, weights):\n",
        "    hid = input.dot(weights[0])\n",
        "    pred = hid.dot(weights[1])\n",
        "    return pred\n",
        "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
        "wlrec = np.array([0.65,0.8, 0.8, 0.9])\n",
        "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
        "input = np.array([toes[0],wlrec[0],nfans[0]])\n",
        "pred = neural_network_6(input,weights)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2135 0.145  0.5065]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQDTRWt5Vz2d",
        "outputId": "5d64be2b-471d-45bd-81b3-a519be0f10d2"
      },
      "source": [
        "knob_weight = 0.5\n",
        "input = 0.5\n",
        "goal_pred = 0.8\n",
        "pred = input * knob_weight\n",
        "error = (pred - goal_pred) ** 2\n",
        "print(error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30250000000000005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr1C2JHAVz5F",
        "outputId": "fb43e76c-b831-47b8-95ec-74826cdf3674"
      },
      "source": [
        "def neural_network_7(input, weight):\n",
        "    pred = input * weight\n",
        "    return pred\n",
        "\n",
        "weight = 0.1\n",
        "lr =0.01\n",
        "\n",
        "number_of_toes = [8.5]\n",
        "win_or_lose_binary = [1] # (победа!!!)\n",
        "input = number_of_toes[0]\n",
        "true = win_or_lose_binary[0]\n",
        "\n",
        "pred = neural_network_7(input, weight)\n",
        "error = (pred - true) ** 2\n",
        "print(error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.022499999999999975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeMwkqcHVz8d",
        "outputId": "b1734004-2df3-47ae-fa16-5e518831619e"
      },
      "source": [
        "lr = 0.1\n",
        "p_up = neural_network_7(input, weight) + lr\n",
        "e_up = (p_up - true) ** 2\n",
        "print(e_up)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0024999999999999935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8HNQlDIVz-N",
        "outputId": "45ab805f-d776-4177-dbe3-ba63fc92f433"
      },
      "source": [
        "lr = 0.01 \n",
        "p_dn = neural_network_7(input,weight - lr)\n",
        "e_dn = (p_dn - true) ** 2\n",
        "print(e_dn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05522499999999994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QaiFOpaXCM2",
        "outputId": "6a477d2e-cb93-40ff-fc2c-921798ab796d"
      },
      "source": [
        "if (error > e_dn or error > e_up):\n",
        "    if(e_dn < e_up):\n",
        "        weight -= lr\n",
        "    if(e_up < e_up):\n",
        "        weight += lr\n",
        "print(weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny9_yUjzVz__",
        "outputId": "a06e4924-3bd0-44bb-c993-b1b0b77b3d84"
      },
      "source": [
        "weight = 0.5\n",
        "input = 0.5\n",
        "goal_prediction = 0.8\n",
        "step_amount = 0.001\n",
        "\n",
        "for iteration in range(1101):\n",
        "    prediction = input * weight\n",
        "    error = (prediction - goal_prediction) ** 2\n",
        "\n",
        "    if iteration == 0:\n",
        "        print(\"Error:\" + str(error) + \" Prediction:\" + str(prediction))\n",
        "    up_prediction = input * (weight + step_amount)\n",
        "    up_error = (goal_prediction - up_prediction) ** 2\n",
        "\n",
        "    down_prediction = input * (weight - step_amount)\n",
        "    down_error = (goal_prediction - down_prediction) ** 2\n",
        "\n",
        "    if(down_error < up_error):\n",
        "        weight = weight - step_amount\n",
        "    if(down_error > up_error):\n",
        "        weight = weight + step_amount\n",
        "\n",
        "print(\"Error:\" + str(error) + \" Prediction:\" + str(prediction))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:0.30250000000000005 Prediction:0.25\n",
            "Error:1.0799505792475652e-27 Prediction:0.7999999999999672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZdKnFoWV0Bp",
        "outputId": "6fdd8fb0-8386-4cf8-95c3-2d4bde5f8ca8"
      },
      "source": [
        "weight = 0.5\n",
        "goal_pred =0.8\n",
        "input =0.5 \n",
        "\n",
        "for iteration in range(20): \n",
        "    pred = input * weight\n",
        "    error = (pred - goal_pred) ** 2\n",
        "    direction_and_amount = (pred - goal_pred) * input\n",
        "    weight = weight - direction_and_amount\n",
        "    if iteration == 0:\n",
        "        print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))\n",
        "\n",
        "print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:0.30250000000000005 Prediction:0.25\n",
            "Error:5.408208020258491e-06 Prediction:0.7976744445781151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlET3gc0V0E2",
        "outputId": "7edbc0c8-7223-454e-e16e-02678582d96b"
      },
      "source": [
        "weight =0.5\n",
        "goal_pred =0.8\n",
        "input =0.5\n",
        "for iteration in range(20):\n",
        "    pred = input * weight\n",
        "    error = (pred - goal_pred) ** 2\n",
        "    delta = pred - goal_pred\n",
        "    weight_delta = input * delta\n",
        "    weight = weight - weight_delta\n",
        "    print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:0.30250000000000005 Prediction:0.25\n",
            "Error:0.17015625000000004 Prediction:0.3875\n",
            "Error:0.095712890625 Prediction:0.49062500000000003\n",
            "Error:0.05383850097656251 Prediction:0.56796875\n",
            "Error:0.03028415679931642 Prediction:0.6259765625\n",
            "Error:0.0170348381996155 Prediction:0.669482421875\n",
            "Error:0.00958209648728372 Prediction:0.70211181640625\n",
            "Error:0.005389929274097089 Prediction:0.7265838623046875\n",
            "Error:0.0030318352166796153 Prediction:0.7449378967285156\n",
            "Error:0.0017054073093822882 Prediction:0.7587034225463867\n",
            "Error:0.0009592916115275371 Prediction:0.76902756690979\n",
            "Error:0.0005396015314842384 Prediction:0.7767706751823426\n",
            "Error:0.000303525861459885 Prediction:0.7825780063867569\n",
            "Error:0.00017073329707118678 Prediction:0.7869335047900676\n",
            "Error:9.603747960254256e-05 Prediction:0.7902001285925507\n",
            "Error:5.402108227642978e-05 Prediction:0.7926500964444131\n",
            "Error:3.038685878049206e-05 Prediction:0.7944875723333098\n",
            "Error:1.7092608064027242e-05 Prediction:0.7958656792499823\n",
            "Error:9.614592036015323e-06 Prediction:0.7968992594374867\n",
            "Error:5.408208020258491e-06 Prediction:0.7976744445781151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PetjjD1b67X",
        "outputId": "ab96ae2e-4cba-46bb-dc6f-d3164f0d6ad0"
      },
      "source": [
        "weight = 0.5\n",
        "goal_pred = 0.8\n",
        "input = 2\n",
        "alpha = 0.1\n",
        "\n",
        "for iteration in range(20):\n",
        "    pred = input * weight\n",
        "    error = (pred - goal_pred) ** 2\n",
        "    derivative = input * (pred - goal_pred)\n",
        "    weight = weight - (alpha * derivative)\n",
        "    print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:0.03999999999999998 Prediction:1.0\n",
            "Error:0.0144 Prediction:0.92\n",
            "Error:0.005183999999999993 Prediction:0.872\n",
            "Error:0.0018662400000000014 Prediction:0.8432000000000001\n",
            "Error:0.0006718464000000028 Prediction:0.8259200000000001\n",
            "Error:0.00024186470400000033 Prediction:0.815552\n",
            "Error:8.70712934399997e-05 Prediction:0.8093312\n",
            "Error:3.134566563839939e-05 Prediction:0.80559872\n",
            "Error:1.1284439629823931e-05 Prediction:0.803359232\n",
            "Error:4.062398266736526e-06 Prediction:0.8020155392\n",
            "Error:1.4624633760252567e-06 Prediction:0.8012093235200001\n",
            "Error:5.264868153690924e-07 Prediction:0.8007255941120001\n",
            "Error:1.8953525353291194e-07 Prediction:0.8004353564672001\n",
            "Error:6.82326912718715e-08 Prediction:0.8002612138803201\n",
            "Error:2.456376885786678e-08 Prediction:0.8001567283281921\n",
            "Error:8.842956788836216e-09 Prediction:0.8000940369969153\n",
            "Error:3.1834644439835434e-09 Prediction:0.8000564221981492\n",
            "Error:1.1460471998340758e-09 Prediction:0.8000338533188895\n",
            "Error:4.125769919393652e-10 Prediction:0.8000203119913337\n",
            "Error:1.485277170987127e-10 Prediction:0.8000121871948003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDkZU5yreUty",
        "outputId": "f10d5546-72d8-4771-b2c5-1a275dae4386"
      },
      "source": [
        "weight = 0.1\n",
        "goal_pred = 0.8\n",
        "input = 2\n",
        "alpha = 0.1\n",
        "\n",
        "for i in range(20):\n",
        "    pred = input * weight\n",
        "    delta = pred - goal_pred\n",
        "    error = delta ** 2\n",
        "    derivative = input * delta\n",
        "    weight = weight - (alpha * derivative)\n",
        "    print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:0.3600000000000001 Prediction:0.2\n",
            "Error:0.1296 Prediction:0.44000000000000006\n",
            "Error:0.04665599999999999 Prediction:0.5840000000000001\n",
            "Error:0.016796159999999984 Prediction:0.6704000000000001\n",
            "Error:0.0060466175999999905 Prediction:0.7222400000000001\n",
            "Error:0.0021767823359999925 Prediction:0.7533440000000001\n",
            "Error:0.0007836416409599973 Prediction:0.7720064000000001\n",
            "Error:0.00028211099074559827 Prediction:0.7832038400000001\n",
            "Error:0.00010155995666841538 Prediction:0.7899223040000001\n",
            "Error:3.656158440063007e-05 Prediction:0.7939533824\n",
            "Error:1.3162170384226505e-05 Prediction:0.7963720294400001\n",
            "Error:4.738381338321348e-06 Prediction:0.7978232176640001\n",
            "Error:1.7058172817956273e-06 Prediction:0.7986939305984001\n",
            "Error:6.140942214464955e-07 Prediction:0.79921635835904\n",
            "Error:2.2107391972069662e-07 Prediction:0.7995298150154241\n",
            "Error:7.958661109946331e-08 Prediction:0.7997178890092544\n",
            "Error:2.8651179995814308e-08 Prediction:0.7998307334055527\n",
            "Error:1.031442479848413e-08 Prediction:0.7998984400433317\n",
            "Error:3.713192927454287e-09 Prediction:0.799939064025999\n",
            "Error:1.336749453880296e-09 Prediction:0.7999634384155995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkdwxU6yfDHB",
        "outputId": "8fadb78c-736a-4f19-9072-031fe8bd1063"
      },
      "source": [
        "weight = 0.1\n",
        "goal_pred = 0.8\n",
        "input = 2\n",
        "alpha = 0.1\n",
        "\n",
        "for i in range(20):\n",
        "    pred = weight * input\n",
        "    delta = pred - goal_pred\n",
        "    error = delta ** 2\n",
        "    derivative = input * delta\n",
        "    weight = weight - alpha * derivative\n",
        "    print(\"Error:\" + str(error) + \" Prediction:\" + str(pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:0.3600000000000001 Prediction:0.2\n",
            "Error:0.1296 Prediction:0.44000000000000006\n",
            "Error:0.04665599999999999 Prediction:0.5840000000000001\n",
            "Error:0.016796159999999984 Prediction:0.6704000000000001\n",
            "Error:0.0060466175999999905 Prediction:0.7222400000000001\n",
            "Error:0.0021767823359999925 Prediction:0.7533440000000001\n",
            "Error:0.0007836416409599973 Prediction:0.7720064000000001\n",
            "Error:0.00028211099074559827 Prediction:0.7832038400000001\n",
            "Error:0.00010155995666841538 Prediction:0.7899223040000001\n",
            "Error:3.656158440063007e-05 Prediction:0.7939533824\n",
            "Error:1.3162170384226505e-05 Prediction:0.7963720294400001\n",
            "Error:4.738381338321348e-06 Prediction:0.7978232176640001\n",
            "Error:1.7058172817956273e-06 Prediction:0.7986939305984001\n",
            "Error:6.140942214464955e-07 Prediction:0.79921635835904\n",
            "Error:2.2107391972069662e-07 Prediction:0.7995298150154241\n",
            "Error:7.958661109946331e-08 Prediction:0.7997178890092544\n",
            "Error:2.8651179995814308e-08 Prediction:0.7998307334055527\n",
            "Error:1.031442479848413e-08 Prediction:0.7998984400433317\n",
            "Error:3.713192927454287e-09 Prediction:0.799939064025999\n",
            "Error:1.336749453880296e-09 Prediction:0.7999634384155995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy-SamjWlcfJ",
        "outputId": "699e100f-7460-4af1-9d61-324095e67465"
      },
      "source": [
        "def neural_network(input, weights):\n",
        "    out = 0\n",
        "    for i in range(len(input)):\n",
        "        out += (input[i] * weights[i])\n",
        "    return out\n",
        "    \n",
        "def ele_mul(scalar, vector):\n",
        "    out = [0,0,0]\n",
        "    for i in range(len(out)):\n",
        "        out[i] = vector[i] * scalar\n",
        "    return out\n",
        "    \n",
        "toes = [8.5, 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "nfans = [1.2, 1.3, 0.5, 1.0]\n",
        "win_or_lose_binary = [1, 1, 0, 1]\n",
        "true = win_or_lose_binary[0]\n",
        "alpha = 0.01\n",
        "weights = [0.1, 0.2, -.1]\n",
        "input = [toes[0], wlrec[0], nfans[0]] \n",
        "\n",
        "for iter in range(3):\n",
        "    pred = neural_network(input,weights)\n",
        "    error = (pred - true) ** 2\n",
        "    delta = pred - true\n",
        "    weight_deltas=ele_mul(delta,input)\n",
        "    print(\"Iteration:\" + str(iter + 1))\n",
        "    print(\"Pred:\" + str(pred))\n",
        "    print(\"Error:\" + str(error))\n",
        "    print(\"Delta:\" + str(delta))\n",
        "    print(\"Weights:\" + str(weights))\n",
        "    print(\"Weight_Deltas:\")\n",
        "    print(str(weight_deltas))\n",
        "    print()\n",
        "    \n",
        "    for i in range(len(weights)):\n",
        "        weights[i]-=alpha*weight_deltas[i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:1\n",
            "Pred:0.8600000000000001\n",
            "Error:0.01959999999999997\n",
            "Delta:-0.1399999999999999\n",
            "Weights:[0.1, 0.2, -0.1]\n",
            "Weight_Deltas:\n",
            "[-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n",
            "\n",
            "Iteration:2\n",
            "Pred:0.9637574999999999\n",
            "Error:0.0013135188062500048\n",
            "Delta:-0.036242500000000066\n",
            "Weights:[0.1119, 0.20091, -0.09832]\n",
            "Weight_Deltas:\n",
            "[-0.30806125000000056, -0.023557625000000044, -0.04349100000000008]\n",
            "\n",
            "Iteration:3\n",
            "Pred:0.9906177228125002\n",
            "Error:8.802712522307997e-05\n",
            "Delta:-0.009382277187499843\n",
            "Weights:[0.11498061250000001, 0.20114557625, -0.09788509000000001]\n",
            "Weight_Deltas:\n",
            "[-0.07974935609374867, -0.006098480171874899, -0.011258732624999811]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOR5mUT3lcoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b2934d-a53d-4b96-c503-843f9f8295bb"
      },
      "source": [
        "def neural_network(input, weights):\n",
        "    out = 0\n",
        "    for i in range(len(input)):\n",
        "        out += (input[i] * weights[i])\n",
        "    return out\n",
        "    \n",
        "def ele_mul(scalar, vector):\n",
        "    out = [0,0,0]\n",
        "    for i in range(len(out)):\n",
        "        out[i] = vector[i] * scalar\n",
        "    return out\n",
        "    \n",
        "toes = [8.5, 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "nfans = [1.2, 1.3, 0.5, 1.0]\n",
        "\n",
        "win_or_lose_binary = [1, 1, 0, 1]\n",
        "true = win_or_lose_binary[0]\n",
        "\n",
        "alpha = 0.3\n",
        "weights = [0.1, 0.2, -.1]\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "\n",
        "for iter in range(3):\n",
        "    pred = neural_network(input,weights)\n",
        "    error = (pred - true) ** 2\n",
        "    delta = pred - true\n",
        "    weight_deltas = ele_mul(delta, input)\n",
        "    weight_deltas[0] = 0\n",
        "    \n",
        "    print(\"Iteration:\" + str(iter+1))\n",
        "    print(\"Pred:\" + str(pred))\n",
        "    print(\"Error:\" + str(error))\n",
        "    print(\"Delta:\" + str(delta))\n",
        "    print(\"Weights:\" + str(weights))\n",
        "    print(\"Weight-Deltas:\")\n",
        "    print(str(weight_deltas))\n",
        "    print()\n",
        "    \n",
        "    for i in range(len(weights)):\n",
        "        weights[i]-=alpha*weight_deltas[i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:1\n",
            "Pred:0.8600000000000001\n",
            "Error:0.01959999999999997\n",
            "Delta:-0.1399999999999999\n",
            "Weights:[0.1, 0.2, -0.1]\n",
            "Weight-Deltas:\n",
            "[0, -0.09099999999999994, -0.16799999999999987]\n",
            "\n",
            "Iteration:2\n",
            "Pred:0.9382250000000001\n",
            "Error:0.003816150624999989\n",
            "Delta:-0.06177499999999991\n",
            "Weights:[0.1, 0.2273, -0.04960000000000005]\n",
            "Weight-Deltas:\n",
            "[0, -0.040153749999999946, -0.07412999999999989]\n",
            "\n",
            "Iteration:3\n",
            "Pred:0.97274178125\n",
            "Error:0.000743010489422852\n",
            "Delta:-0.027258218750000007\n",
            "Weights:[0.1, 0.239346125, -0.02736100000000008]\n",
            "Weight-Deltas:\n",
            "[0, -0.017717842187500006, -0.032709862500000006]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pOU1SbKlc8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3133530-1ca9-4822-b86e-1b3395fbe112"
      },
      "source": [
        "weights = [0.3, 0.2, 0.9]\n",
        "\n",
        "def neural_network(input, weights):\n",
        "    pred = ele_mul(input,weights)\n",
        "    return pred\n",
        "    \n",
        "wlrec = [0.65, 1.0, 1.0, 0.9]\n",
        "hurt = [0.1, 0.0, 0.0, 0.1]\n",
        "win = [ 1, 1, 0, 1]\n",
        "sad = [0.1, 0.0, 0.1, 0.2]\n",
        "input = wlrec[0]\n",
        "true = [hurt[0], win[0], sad[0]]\n",
        "pred = neural_network(input,weights)\n",
        "error = [0, 0, 0]\n",
        "delta = [0, 0, 0]\n",
        "for i in range(len(true)):\n",
        "    error[i] = (pred[i] - true[i]) ** 2\n",
        "    delta[i] = pred[i] - true[i]\n",
        "\n",
        "def scalar_ele_mul(number,vector):\n",
        "    output = [0,0,0]\n",
        "    assert(len(output) == len(vector))\n",
        "    for i in range(len(vector)):\n",
        "        output[i] = number * vector[i]\n",
        "    return output\n",
        "\n",
        "wlrec = [0.65, 1.0, 1.0, 0.9]\n",
        "hurt = [0.1, 0.0, 0.0, 0.1]\n",
        "win = [ 1, 1, 0, 1]\n",
        "sad = [0.1, 0.0, 0.1, 0.2]\n",
        "\n",
        "input = wlrec[0]\n",
        "true = [hurt[0], win[0], sad[0]]\n",
        "\n",
        "pred = neural_network(input, weights)\n",
        "\n",
        "error = [0, 0, 0]\n",
        "delta = [0, 0,0 ]\n",
        "\n",
        "for i in range(len(true)):\n",
        "    delta[i] = pred[i] - true[i]\n",
        "    error[i] = delta[i] ** 2\n",
        "\n",
        "weight_deltas = scalar_ele_mul(input, weights)\n",
        "input = wlrec[0]\n",
        "true = [hurt[0], win[0], sad[0]]\n",
        "pred = neural_network(input,weights)\n",
        "error = [0, 0, 0]\n",
        "delta = [0, 0, 0]\n",
        "for i in range(len(true)):\n",
        "    error[i] = (pred[i] - true[i]) ** 2\n",
        "    delta[i] = pred[i] - true[i]\n",
        "    weight_deltas = scalar_ele_mul(input,weights)\n",
        "    alpha = 0.1\n",
        "    for i in range(len(weights)):\n",
        "        weights[i] -= (weight_deltas[i] * alpha)\n",
        "    print(\"Weights:\" + str(weights))\n",
        "    print(\"Weight Deltas:\" + str(weight_deltas))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights:[0.28049999999999997, 0.187, 0.8415]\n",
            "Weight Deltas:[0.195, 0.13, 0.5850000000000001]\n",
            "Weights:[0.2622675, 0.174845, 0.7868025000000001]\n",
            "Weight Deltas:[0.182325, 0.12155, 0.546975]\n",
            "Weights:[0.24522011249999998, 0.163480075, 0.7356603375]\n",
            "Weight Deltas:[0.170473875, 0.11364925000000001, 0.5114216250000001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiXroG5zldCZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "bf22bcf2-79cc-45fa-ad2e-4fa0a647836f"
      },
      "source": [
        "weights = [ [0.1, 0.1, -0.3],\n",
        "[0.1, 0.2, 0.0], \n",
        "[0.0, 1.3, 0.1] ]\n",
        "\n",
        "def vect_mat_mul(vect,matrix):\n",
        "    assert(len(vect) == len(matrix))\n",
        "    output = [0,0,0]\n",
        "    for i in range(len(vect)):\n",
        "        output[i] = w_sum(vect,matrix[i])\n",
        "    return output\n",
        "    \n",
        "def neural_network(input, weights):\n",
        "    pred = vect_mat_mul(input,weights)\n",
        "    return pred\n",
        "    \n",
        "toes = [8.5, 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "nfans = [1.2, 1.3, 0.5, 1.0]\n",
        "hurt = [0.1, 0.0, 0.0, 0.1]\n",
        "win = [ 1, 1, 0, 1]\n",
        "sad = [0.1, 0.0, 0.1, 0.2]\n",
        "\n",
        "alpha = 0.01\n",
        "input = [toes[0],wlrec[0],nfans[0]]\n",
        "true = [hurt[0], win[0], sad[0]]\n",
        "pred = neural_network(input,weights)\n",
        "error = [0, 0, 0]\n",
        "delta = [0, 0, 0]\n",
        "\n",
        "for i in range(len(true)):\n",
        "    delta = pred[i] - true[i]\n",
        "    error[i] = delta ** 2\n",
        "\n",
        "def outer_prod(vec_a, vec_b):\n",
        "    out = zeros_matrix(len(a), len(b))\n",
        "    for i in range(len(a)):\n",
        "        for j in range(len(b)):\n",
        "            out[i][j] = vec_a[i]*vec_b[j]\n",
        "    return out\n",
        "    \n",
        "input = [toes[0],wlrec[0], nfans[0]]\n",
        "true = [hurt[0], win[0], sad[0]]\n",
        "pred = neural_network(input,weights)\n",
        "error = [0, 0, 0]\n",
        "delta = [0, 0, 0]\n",
        "\n",
        "for i in range(len(true)):\n",
        "    delta[i] = pred[i] - true[i]\n",
        "    error[i] = delta[i] ** 2\n",
        "    \n",
        "weight_deltas = outer_prod(input,delta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-b27b0a397c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mweight_deltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouter_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-b27b0a397c7a>\u001b[0m in \u001b[0;36mouter_prod\u001b[0;34m(vec_a, vec_b)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mouter_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'zeros_matrix' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC2yAd95ldF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19bcde50-9417-489a-b839-8a5d71f6170e"
      },
      "source": [
        "import numpy as пр\n",
        "weights = пр.array([0.5,0.48,-0.7])\n",
        "alpha = 0.1\n",
        "streetlights = np.array( [[ 1, 0, 1 ],\n",
        "[ 0, 1, 1 ],\n",
        "[ 0, 0, 1 ],\n",
        "[ 1, 1, 1 ],\n",
        "[ 0, 1, 1 ],\n",
        "[ 1, 0, 1 ] ] )\n",
        "\n",
        "walk_vs_stop = np.array( [0, 1, 0, 1, 1, 0] )\n",
        "input = streetlights [0] \n",
        "goal_prediction = walk_vs_stop[0] \n",
        "for iteration in range(40):\n",
        "    error_for_all_lights = 0\n",
        "    for row_index in range(len(walk_vs_stop)):\n",
        "        input = streetlights[row_index]\n",
        "        goal_prediction = walk_vs_stop[row_index]\n",
        "        prediction = input.dot(weights)\n",
        "        error = (goal_prediction - prediction) ** 2\n",
        "        error_for_all_lights += error\n",
        "        delta = prediction - goal_prediction\n",
        "        weights = weights - (alpha * (input * delta))\n",
        "        print(\"Prediction:\" + str(prediction))\n",
        "        print('Error:' + str(error_for_all_lights) + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:-0.19999999999999996\n",
            "Error:0.03999999999999998\n",
            "\n",
            "Prediction:-0.19999999999999996\n",
            "Error:1.48\n",
            "\n",
            "Prediction:-0.5599999999999999\n",
            "Error:1.7935999999999999\n",
            "\n",
            "Prediction:0.6160000000000001\n",
            "Error:1.9410559999999997\n",
            "\n",
            "Prediction:0.17279999999999995\n",
            "Error:2.62531584\n",
            "\n",
            "Prediction:0.17552\n",
            "Error:2.6561231104\n",
            "\n",
            "Prediction:0.14041599999999999\n",
            "Error:0.019716653055999997\n",
            "\n",
            "Prediction:0.3066464\n",
            "Error:0.50045586768896\n",
            "\n",
            "Prediction:-0.34513824\n",
            "Error:0.6195762723992576\n",
            "\n",
            "Prediction:1.006637344\n",
            "Error:0.619620326734632\n",
            "\n",
            "Prediction:0.4785034751999999\n",
            "Error:0.891578952113109\n",
            "\n",
            "Prediction:0.26700416768\n",
            "Error:0.9628701776715985\n",
            "\n",
            "Prediction:0.213603334144\n",
            "Error:0.04562638435743332\n",
            "\n",
            "Prediction:0.5347420299776\n",
            "Error:0.26209136302679775\n",
            "\n",
            "Prediction:-0.26067345110016\n",
            "Error:0.33004201113526527\n",
            "\n",
            "Prediction:1.1319428845096962\n",
            "Error:0.3474509359080043\n",
            "\n",
            "Prediction:0.6274723921901568\n",
            "Error:0.4862277544885286\n",
            "\n",
            "Prediction:0.25433999330650114\n",
            "Error:0.5509165866836797\n",
            "\n",
            "Prediction:0.20347199464520088\n",
            "Error:0.041400852604896655\n",
            "\n",
            "Prediction:0.6561967149569552\n",
            "Error:0.15960155141128576\n",
            "\n",
            "Prediction:-0.221948503950995\n",
            "Error:0.2088626898173706\n",
            "\n",
            "Prediction:1.166258650532124\n",
            "Error:0.23650462869413352\n",
            "\n",
            "Prediction:0.7139004922542389\n",
            "Error:0.3183575570265003\n",
            "\n",
            "Prediction:0.21471099528371604\n",
            "Error:0.36445836852222424\n",
            "\n",
            "Prediction:0.17176879622697283\n",
            "Error:0.029504519357263316\n",
            "\n",
            "Prediction:0.7324724146523222\n",
            "Error:0.10107552827922237\n",
            "\n",
            "Prediction:-0.19966478845083285\n",
            "Error:0.1409415560263382\n",
            "\n",
            "Prediction:1.1697769945341199\n",
            "Error:0.16976578389937677\n",
            "\n",
            "Prediction:0.7719890116601171\n",
            "Error:0.22175479470310697\n",
            "\n",
            "Prediction:0.17297997428859369\n",
            "Error:0.2516768662079895\n",
            "\n",
            "Prediction:0.13838397943087496\n",
            "Error:0.019150125763124824\n",
            "\n",
            "Prediction:0.7864548139561468\n",
            "Error:0.0647516722456287\n",
            "\n",
            "Prediction:-0.1836567869927348\n",
            "Error:0.09848148765412346\n",
            "\n",
            "Prediction:1.163248019006011\n",
            "Error:0.1251314033635104\n",
            "\n",
            "Prediction:0.8148799260629888\n",
            "Error:0.15940084513795488\n",
            "\n",
            "Prediction:0.1362897844408577\n",
            "Error:0.17797575048089034\n",
            "\n",
            "Prediction:0.10903182755268614\n",
            "Error:0.01188793941947869\n",
            "\n",
            "Prediction:0.8273717796510367\n",
            "Error:0.04168844188032892\n",
            "\n",
            "Prediction:-0.17037324196481937\n",
            "Error:0.07071548345793181\n",
            "\n",
            "Prediction:1.1537962739591756\n",
            "Error:0.0943687773416576\n",
            "\n",
            "Prediction:0.8481754931254761\n",
            "Error:0.11741945822934995\n",
            "\n",
            "Prediction:0.1059488041691444\n",
            "Error:0.12864460733422164\n",
            "\n",
            "Prediction:0.0847590433353155\n",
            "Error:0.007184095427117891\n",
            "\n",
            "Prediction:0.859469609749935\n",
            "Error:0.026932886010953446\n",
            "\n",
            "Prediction:-0.1585508402022421\n",
            "Error:0.052071254939790354\n",
            "\n",
            "Prediction:1.1438418857156731\n",
            "Error:0.07276174302603113\n",
            "\n",
            "Prediction:0.8746623946770374\n",
            "Error:0.08847125833412586\n",
            "\n",
            "Prediction:0.08148074110264475\n",
            "Error:0.09511036950476208\n",
            "\n",
            "Prediction:0.06518459288211581\n",
            "Error:0.004249031149207183\n",
            "\n",
            "Prediction:0.8850633823431538\n",
            "Error:0.017459457227603222\n",
            "\n",
            "Prediction:-0.14771905585408038\n",
            "Error:0.03928037669002414\n",
            "\n",
            "Prediction:1.1341830033853888\n",
            "Error:0.0572854550875474\n",
            "\n",
            "Prediction:0.8959860107828534\n",
            "Error:0.06810436504041208\n",
            "\n",
            "Prediction:0.0619780399014222\n",
            "Error:0.07194564247043436\n",
            "\n",
            "Prediction:0.04958243192113776\n",
            "Error:0.0024584175552142605\n",
            "\n",
            "Prediction:0.9056327614440267\n",
            "Error:0.011363593267894233\n",
            "\n",
            "Prediction:-0.13768337501215525\n",
            "Error:0.03032030502263201\n",
            "\n",
            "Prediction:1.1250605910610996\n",
            "Error:0.04596045645918359\n",
            "\n",
            "Prediction:0.9132624284442169\n",
            "Error:0.05348386277857818\n",
            "\n",
            "Prediction:0.04653264583708144\n",
            "Error:0.05564914990717743\n",
            "\n",
            "Prediction:0.03722611666966513\n",
            "Error:0.0013857837623035202\n",
            "\n",
            "Prediction:0.922234066504699\n",
            "Error:0.007433324174699103\n",
            "\n",
            "Prediction:-0.12834662236261596\n",
            "Error:0.023906179646591055\n",
            "\n",
            "Prediction:1.116526024487899\n",
            "Error:0.037484494029545484\n",
            "\n",
            "Prediction:0.9273167105424409\n",
            "Error:0.0427673545959168\n",
            "\n",
            "Prediction:0.03435527296969987\n",
            "Error:0.04394763937673939\n",
            "\n",
            "Prediction:0.027484218375759886\n",
            "Error:0.0007553822597264574\n",
            "\n",
            "Prediction:0.9356694192994068\n",
            "Error:0.004893805873001987\n",
            "\n",
            "Prediction:-0.11964712469387503\n",
            "Error:0.019209240320513667\n",
            "\n",
            "Prediction:1.1085678053734553\n",
            "Error:0.030996208684122145\n",
            "\n",
            "Prediction:0.9387866868342218\n",
            "Error:0.03474327839285377\n",
            "\n",
            "Prediction:0.024792915481941458\n",
            "Error:0.035357967050948465\n",
            "\n",
            "Prediction:0.019834332385553155\n",
            "Error:0.0003934007411806027\n",
            "\n",
            "Prediction:0.946566624680628\n",
            "Error:0.003248526339201473\n",
            "\n",
            "Prediction:-0.11153724870006754\n",
            "Error:0.01568908418678219\n",
            "\n",
            "Prediction:1.1011550767549563\n",
            "Error:0.025921433740083287\n",
            "\n",
            "Prediction:0.948176009263518\n",
            "Error:0.028607159755938263\n",
            "\n",
            "Prediction:0.017315912033043404\n",
            "Error:0.02890700056547436\n",
            "\n",
            "Prediction:0.013852729626434732\n",
            "Error:0.00019189811810310255\n",
            "\n",
            "Prediction:0.9554239432448665\n",
            "Error:0.0021789229539399893\n",
            "\n",
            "Prediction:-0.10397589092234266\n",
            "Error:0.012989908847034888\n",
            "\n",
            "Prediction:1.0942524239871314\n",
            "Error:0.021873428274484873\n",
            "\n",
            "Prediction:0.9558862588907013\n",
            "Error:0.0238194504291431\n",
            "\n",
            "Prediction:0.011498267782398985\n",
            "Error:0.023951660591138853\n",
            "\n",
            "Prediction:0.009198614225919194\n",
            "Error:8.461450367728297e-05\n",
            "\n",
            "Prediction:0.9626393189117293\n",
            "Error:0.0014804349950567532\n",
            "\n",
            "Prediction:-0.09692579020989642\n",
            "Error:0.010875043802869605\n",
            "\n",
            "Prediction:1.087824783849832\n",
            "Error:0.018588236461139326\n",
            "\n",
            "Prediction:0.9622390773804066\n",
            "Error:0.020014123738222245\n",
            "\n",
            "Prediction:0.006998674002545002\n",
            "Error:0.020063105176016144\n",
            "\n",
            "Prediction:0.005598939202035996\n",
            "Error:3.134812018809548e-05\n",
            "\n",
            "Prediction:0.9685315005838672\n",
            "Error:0.0010216145756912478\n",
            "\n",
            "Prediction:-0.09035250869077546\n",
            "Error:0.009185190402407905\n",
            "\n",
            "Prediction:1.0818389613301889\n",
            "Error:0.015882805994012053\n",
            "\n",
            "Prediction:0.9674926590701334\n",
            "Error:0.016939533208342634\n",
            "\n",
            "Prediction:0.003544193999268516\n",
            "Error:0.016952094519447087\n",
            "\n",
            "Prediction:0.0028353551994148157\n",
            "Error:8.03923910684863e-06\n",
            "\n",
            "Prediction:0.9733561723362383\n",
            "Error:0.000717932791683083\n",
            "\n",
            "Prediction:-0.0842239920152223\n",
            "Error:0.007811613622663312\n",
            "\n",
            "Prediction:1.0762639960116431\n",
            "Error:0.013627810710327232\n",
            "\n",
            "Prediction:0.9718545378681842\n",
            "Error:0.014419977748940709\n",
            "\n",
            "Prediction:0.0009168131382832068\n",
            "Error:0.014420818295271236\n",
            "\n",
            "Prediction:0.0007334505106265654\n",
            "Error:5.379496515383696e-07\n",
            "\n",
            "Prediction:0.9773186039296565\n",
            "Error:0.0005149836773513307\n",
            "\n",
            "Prediction:-0.07851033295953944\n",
            "Error:0.006678856058769075\n",
            "\n",
            "Prediction:1.0710711494147542\n",
            "Error:0.011729964337903395\n",
            "\n",
            "Prediction:0.9754916865567282\n",
            "Error:0.01233062176573705\n",
            "\n",
            "Prediction:-0.0010574652271341245\n",
            "Error:0.012331739998443648\n",
            "\n",
            "Prediction:-0.0008459721817072885\n",
            "Error:7.156689322225895e-07\n",
            "\n",
            "Prediction:0.9805836929862668\n",
            "Error:0.00037770864698376776\n",
            "\n",
            "Prediction:-0.07318360881847627\n",
            "Error:0.005733549246679526\n",
            "\n",
            "Prediction:1.066233777045345\n",
            "Error:0.010120462468371989\n",
            "\n",
            "Prediction:0.9785385598617921\n",
            "Error:0.010581055881177873\n",
            "\n",
            "Prediction:-0.0025173975573930946\n",
            "Error:0.010587393171639842\n",
            "\n",
            "Prediction:-0.002013918045914484\n",
            "Error:4.055865895660013e-06\n",
            "\n",
            "Prediction:0.9832839794497644\n",
            "Error:0.0002834812089315581\n",
            "\n",
            "Prediction:-0.06821774801198803\n",
            "Error:0.004937142352758655\n",
            "\n",
            "Prediction:1.0617271739912904\n",
            "Error:0.008747386361709688\n",
            "\n",
            "Prediction:0.9811035235627523\n",
            "Error:0.009104463183453145\n",
            "\n",
            "Prediction:-0.0035735447350425317\n",
            "Error:0.009117233405426495\n",
            "\n",
            "Prediction:-0.002858835788034024\n",
            "Error:8.172942062944119e-06\n",
            "\n",
            "Prediction:0.9855260569025094\n",
            "Error:0.00021766797085234036\n",
            "\n",
            "Prediction:-0.06358841060413677\n",
            "Error:0.004261153934012634\n",
            "\n",
            "Prediction:1.05752842286588\n",
            "Error:0.007570673371448126\n",
            "\n",
            "Prediction:0.9832740020092452\n",
            "Error:0.00785043238023486\n",
            "\n",
            "Prediction:-0.004313918034364962\n",
            "Error:0.00786904226904208\n",
            "\n",
            "Prediction:-0.003451134427491974\n",
            "Error:1.1910328836620354e-05\n",
            "\n",
            "Prediction:0.9873957068535818\n",
            "Error:0.00017077853455746514\n",
            "\n",
            "Prediction:-0.059272877470408075\n",
            "Error:0.0036840525381794742\n",
            "\n",
            "Prediction:1.0536162524729626\n",
            "Error:0.006558755067423947\n",
            "\n",
            "Prediction:0.9851206027353137\n",
            "Error:0.006780151530384302\n",
            "\n",
            "Prediction:-0.004808501248434842\n",
            "Error:0.006803273214640502\n",
            "\n",
            "Prediction:-0.0038468009987478735\n",
            "Error:1.4797877923967637e-05\n",
            "\n",
            "Prediction:0.9889620124129692\n",
            "Error:0.0001366350478954133\n",
            "\n",
            "Prediction:-0.05524994626077355\n",
            "Error:0.0031891916097137782\n",
            "\n",
            "Prediction:1.049970908776931\n",
            "Error:0.005686283333706127\n",
            "\n",
            "Prediction:0.9867004228010665\n",
            "Error:0.005863162087376519\n",
            "\n",
            "Prediction:-0.005112871449710697\n",
            "Error:0.005889303541837786\n",
            "\n",
            "Prediction:-0.004090297159768559\n",
            "Error:1.6730530855210743e-05\n",
            "\n",
            "Prediction:0.9902806551018011\n",
            "Error:0.00011119619610535617\n",
            "\n",
            "Prediction:-0.051499833441728114\n",
            "Error:0.0027634290406310935\n",
            "\n",
            "Prediction:1.0465740376293469\n",
            "Error:0.004932570021730911\n",
            "\n",
            "Prediction:0.9880596998997442\n",
            "Error:0.0050751407882150806\n",
            "\n",
            "Prediction:-0.0052710974096659285\n",
            "Error:0.0051029252561172675\n",
            "\n",
            "Prediction:-0.004216877927732746\n",
            "Error:1.7782059457399616e-05\n",
            "\n",
            "Prediction:0.9913965574535352\n",
            "Error:9.180128310772094e-05\n",
            "\n",
            "Prediction:-0.048004082062078055\n",
            "Error:0.0023961931777304454\n",
            "\n",
            "Prediction:1.043408578143574\n",
            "Error:0.004280497834177217\n",
            "\n",
            "Prediction:0.9892359385403211\n",
            "Error:0.004396362853284962\n",
            "\n",
            "Prediction:-0.005318059364078823\n",
            "Error:0.004424644608684828\n",
            "\n",
            "Prediction:-0.0042544474912630525\n",
            "Error:1.810032345591448e-05\n",
            "\n",
            "Prediction:0.992346001517791\n",
            "Error:7.668401622157286e-05\n",
            "\n",
            "Prediction:-0.044745474990504665\n",
            "Error:0.0020788415483474513\n",
            "\n",
            "Prediction:1.0404586655589985\n",
            "Error:0.00371574516716234\n",
            "\n",
            "Prediction:0.9902596156014837\n",
            "Error:0.0038106202553932\n",
            "\n",
            "Prediction:-0.005281305317687134\n",
            "Error:0.0038385124412518303\n",
            "\n",
            "Prediction:-0.0042250442541497055\n",
            "Error:1.785099894952344e-05\n",
            "\n",
            "Prediction:0.9931583274383705\n",
            "Error:6.465948239007722e-05\n",
            "\n",
            "Prediction:-0.041707953394155776\n",
            "Error:0.0018042128587191476\n",
            "\n",
            "Prediction:1.0377095425371112\n",
            "Error:0.003226222457077349\n",
            "\n",
            "Prediction:0.9911555487826897\n",
            "Error:0.00330444677441273\n",
            "\n",
            "Prediction:-0.005182536193432452\n",
            "Error:0.0033313054558089675\n",
            "\n",
            "Prediction:-0.004146028954745959\n",
            "Error:1.7189556093591867e-05\n",
            "\n",
            "Prediction:0.9938572955409696\n",
            "Error:5.492237416458412e-05\n",
            "\n",
            "Prediction:-0.03887654022599941\n",
            "Error:0.0015663077541083342\n",
            "\n",
            "Prediction:1.0351474779634813\n",
            "Error:0.002801652961301736\n",
            "\n",
            "Prediction:0.9919439948626794\n",
            "Error:0.0028665521800742724\n",
            "\n",
            "Prediction:-0.00503879377425797\n",
            "Error:0.0028919416227737734\n",
            "\n",
            "Prediction:-0.004031035019406375\n",
            "Error:1.624924332768055e-05\n",
            "\n",
            "Prediction:0.9944621787695098\n",
            "Error:4.691670730854833e-05\n",
            "\n",
            "Prediction:-0.03623726848360008\n",
            "Error:0.0013600563344610638\n",
            "\n",
            "Prediction:1.032759692455092\n",
            "Error:0.0024332537842132696\n",
            "\n",
            "Prediction:0.9926415313729495\n",
            "Error:0.0024874008447485557\n",
            "\n",
            "Prediction:-0.004863410672429416\n",
            "Error:0.002511053608117256\n",
            "\n",
            "Prediction:-0.003890728537943533\n",
            "Error:1.5137768555968222e-05\n",
            "\n",
            "Prediction:0.9949886390193969\n",
            "Error:4.025150743387912e-05\n",
            "\n",
            "Prediction:-0.03377711399894662\n",
            "Error:0.0011811449375317147\n",
            "\n",
            "Prediction:1.0305342898820642\n",
            "Error:0.0021134877961336423\n",
            "\n",
            "Prediction:0.9932617646389992\n",
            "Error:0.002158891611913884\n",
            "\n",
            "Prediction:-0.004666769772712614\n",
            "Error:0.0021806703520253884\n",
            "\n",
            "Prediction:-0.003733415818170091\n",
            "Error:1.393839367136265e-05\n",
            "\n",
            "Prediction:0.9954494302702878\n",
            "Error:3.464607853633597e-05\n",
            "\n",
            "Prediction:-0.03148393251909879\n",
            "Error:0.0010258840854035023\n",
            "\n",
            "Prediction:1.0284601943056741\n",
            "Error:0.0018358667453202294\n",
            "\n",
            "Prediction:0.9938158986070053\n",
            "Error:0.0018741098553590688\n",
            "\n",
            "Prediction:-0.004456911151490314\n",
            "Error:0.0018939739123713475\n",
            "\n",
            "Prediction:-0.003565528921192253\n",
            "Error:1.271299648785839e-05\n",
            "\n",
            "Prediction:0.9958549628928723\n",
            "Error:2.9894329107323617e-05\n",
            "\n",
            "Prediction:-0.029346400840475826\n",
            "Error:0.0008911055713972039\n",
            "\n",
            "Prediction:1.0265270918125804\n",
            "Error:0.0015947921714302737\n",
            "\n",
            "Prediction:0.9943131920358295\n",
            "Error:0.0016271319562516271\n",
            "\n",
            "Prediction:-0.004240016908292479\n",
            "Error:0.0016451096996342332\n",
            "\n",
            "Prediction:-0.0033920135266339822\n",
            "Error:1.1505755764867905e-05\n",
            "\n",
            "Prediction:0.9962137566721563\n",
            "Error:2.5841394302508984e-05\n",
            "\n",
            "Prediction:-0.02735396176499221\n",
            "Error:0.0007740806185431648\n",
            "\n",
            "Prediction:1.0247253767906936\n",
            "Error:0.0013854248759849366\n",
            "\n",
            "Prediction:0.9947613261560856\n",
            "Error:0.0014128685796278497\n",
            "\n",
            "Prediction:-0.004020798285770878\n",
            "Error:0.0014290353984827077\n",
            "\n",
            "Prediction:-0.003216638628616701\n",
            "Error:1.0346764067109132e-05\n",
            "\n",
            "Prediction:0.9965328046163073\n",
            "Error:2.236820789580887e-05\n",
            "\n",
            "Prediction:-0.025496772653362886\n",
            "Error:0.0006724536236330824\n",
            "\n",
            "Prediction:1.0230461022472208\n",
            "Error:0.0012035764524224385\n",
            "\n",
            "Prediction:0.9951667005089379\n",
            "Error:0.0012269372363927402\n",
            "\n",
            "Prediction:-0.0038028045995257484\n",
            "Error:0.0012413985592149145\n",
            "\n",
            "Prediction:-0.003042243679620596\n",
            "Error:9.255246606191463e-06\n",
            "\n",
            "Prediction:0.996817865235065\n",
            "Error:1.938122826839944e-05\n",
            "\n",
            "Prediction:-0.023765657359234325\n",
            "Error:0.0005841876979849281\n",
            "\n",
            "Prediction:1.0214809338160067\n",
            "Error:0.0010456182155925877\n",
            "\n",
            "Prediction:0.995534671160774\n",
            "Error:0.0010655573772350112\n",
            "\n",
            "Prediction:-0.0035886696105582767\n",
            "Error:0.0010784359268087556\n",
            "\n",
            "Prediction:-0.0028709356884466207\n",
            "Error:8.242271727196472e-06\n",
            "\n",
            "Prediction:0.9970736974585198\n",
            "Error:1.6805518291469868e-05\n",
            "\n",
            "Prediction:-0.022152061336940452\n",
            "Error:0.0005075193397670419\n",
            "\n",
            "Prediction:1.0200221071408409\n",
            "Error:0.0009084041141263521\n",
            "\n",
            "Prediction:0.9958697426723416\n",
            "Error:0.0009254631397190278\n",
            "\n",
            "Prediction:-0.0033803078583175654\n",
            "Error:0.0009368896209360312\n",
            "\n",
            "Prediction:-0.0027042462866540516\n",
            "Error:7.312947978882227e-06\n",
            "\n",
            "Prediction:0.9973042495523706\n",
            "Error:1.4580018454776203e-05\n",
            "\n",
            "Prediction:-0.02064800972530455\n",
            "Error:0.00044092032407104753\n",
            "\n",
            "Prediction:1.018662388355171\n",
            "Error:0.000789205063190273\n",
            "\n",
            "Prediction:0.9961757229433927\n",
            "Error:0.0008038301581959656\n",
            "\n",
            "Prediction:-0.0031790709774033414\n",
            "Error:0.0008139366504753339\n",
            "\n",
            "Prediction:-0.002543256781922673\n",
            "Error:6.468155058795671e-06\n",
            "\n",
            "Prediction:0.9975128111306469\n",
            "Error:1.2654263530629438e-05\n",
            "\n",
            "Prediction:-0.019246068219762574\n",
            "Error:0.00038306540545038435\n",
            "\n",
            "Prediction:1.0173950374076535\n",
            "Error:0.0006856527318640478\n",
            "\n",
            "Prediction:0.9964558482449631\n",
            "Error:0.0006982137435267787\n",
            "\n",
            "Prediction:-0.0029858720226535913\n",
            "Error:0.0007071291752624441\n",
            "\n",
            "Prediction:-0.002388697618122871\n",
            "Error:5.705876310825877e-06\n",
            "\n",
            "Prediction:0.9977021355600483\n",
            "Error:1.0986057295220529e-05\n",
            "\n",
            "Prediction:-0.01793930655497516\n",
            "Error:0.00033280477696859533\n",
            "\n",
            "Prediction:1.0162137740080082\n",
            "Error:0.0005956912445513565\n",
            "\n",
            "Prediction:0.9967128843019345\n",
            "Error:0.0006064963741638251\n",
            "\n",
            "Prediction:-0.0028012842268006904\n",
            "Error:0.0006143435674831474\n",
            "\n",
            "Prediction:-0.0022410273814405524\n",
            "Error:5.022203724366299e-06\n",
            "\n",
            "Prediction:0.9978745386023716\n",
            "Error:9.539789877174641e-06\n",
            "\n",
            "Prediction:-0.016721264429884947\n",
            "Error:0.0002891404740113102\n",
            "\n",
            "Prediction:1.0151127459893812\n",
            "Error:0.0005175355653508669\n",
            "\n",
            "Prediction:0.9969492081270097\n",
            "Error:0.0005268428964031705\n",
            "\n",
            "Prediction:-0.0026256193329783125\n",
            "Error:0.00053373677328488\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVNeITyW-jtY"
      },
      "source": [
        "**Функция активации** (англ. activation function) **a(x)** - определяет выходное значение нейрона в зависимости от результата взвешенной суммы входов и порогового значения.\n",
        "\n",
        "**Ограничения функции активации**:\n",
        "- непрерывна и бесконечна на всей области определения\n",
        "- монотонна и не меняет направление (немонотонные можно оптимизировать)\n",
        "- нелинейна (имеет точки перегиба): для создания эпизодической корреляции\n",
        "- имеет низкую вычислительную сложность\n",
        "\n",
        "**Rectified Linear Unit (ReLU)** - функция активации, возвращает 0, если принимает отрицательный аргумент, в случае же положительного аргумента, функция возвращает само число. \n",
        "\n",
        "Функцию активации ReLU следует использовать, если нет особых требований для выходного значения нейрона, вроде неограниченной области определения. Но если после обучения модели результаты получились не оптимальные, то стоит перейти к другим функциям, которые могут дать лучший результат."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw9IhQJCldI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb1e3d3-9888-4422-b8fb-b91f17381c8c"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "\n",
        "# ReLU\n",
        "def relu(x):\n",
        "    return (x > 0) * x\n",
        "\n",
        "# derivative of ReLU\n",
        "def relu2deriv(output):\n",
        "    return output > 0\n",
        "\n",
        "\n",
        "alpha = 0.2                 # correction coeff\n",
        "hidden_size = 4             # IDK\n",
        "\n",
        "streetlights = np.array( [  # data to learn\n",
        "    [ 1, 0, 1 ],\n",
        "    [ 0, 1, 1 ],\n",
        "    [ 0, 0, 1 ],\n",
        "    [ 1, 1, 1 ] \n",
        "] )\n",
        "walk_vs_stop = np.array([[1, 1, 0, 0]]).T   # teacher\n",
        "\n",
        "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1    # weights for 1st layer\n",
        "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1    # weights for 2nd layer\n",
        "\n",
        "for iteration in range(60):\n",
        "    layer_2_error = 0                   # 1st error for layer 2\n",
        "    for i in range(len(streetlights)):\n",
        "        layer_0 = streetlights[i:i+1]                                               # take some data from all\n",
        "        layer_1 = relu(np.dot(layer_0, weights_0_1))                                # multiply 2 vectors and check the result with ReLU\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)                                      # take a result for layer 2\n",
        "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)               # calculate an error for 2nd layer\n",
        "        layer_2_delta = walk_vs_stop[i:i+1] - layer_2                               # calculate a delta between teaching data and prediction\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)      # 1) calculate a derivative with ReLU\n",
        "                                                                                    # 2) multiply vectors of weights from 2nd layer and 2nd delta\n",
        "                                                                                    # 3) multiply derivative and last result\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)                         # recalculate 2nd layer weights \n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)                         # recalculate 1st layer weights\n",
        "    if (iteration % 10 == 9):\n",
        "        print (\"Error:\" + str(layer_2_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:0.6342311598444467\n",
            "Error:0.3583840767631751\n",
            "Error:0.08301831133032973\n",
            "Error:0.006467054957103672\n",
            "Error:0.0003292669000750735\n",
            "Error:1.5055622665134864e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2skTOwgldMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509c181e-572c-445f-b0f2-8991b796cadb"
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "def relu(x):\n",
        "    return (x > 0) * x\n",
        "\n",
        "def relu2deriv(output):\n",
        "    return output > 0\n",
        "\n",
        "alpha = 0.2\n",
        "hidden_size = 4\n",
        "\n",
        "streetlights = np.array( [  # data to learn\n",
        "    [ 1, 0, 1 ],\n",
        "    [ 0, 1, 1 ],\n",
        "    [ 0, 0, 1 ],\n",
        "    [ 1, 1, 1 ] \n",
        "] )\n",
        "walk_vs_stop = np.array([[1, 1, 0, 0]]).T   # teacher\n",
        "\n",
        "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1    # weights for 1st layer\n",
        "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1    # weights for 2nd layer\n",
        "\n",
        "for iteration in range(60):\n",
        "    layer_2_error = 0\n",
        "    for i in range(len(streetlights)):\n",
        "        layer_0 = streetlights[i:i+1]   \n",
        "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)\n",
        "        \n",
        "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
        "        layer_2_delta = walk_vs_stop[i:i+1] - layer_2\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "\n",
        "\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "    if (iteration % 10 == 9):\n",
        "        print (\"Error:\" + str(layer_2_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:0.6342311598444467\n",
            "Error:0.3583840767631751\n",
            "Error:0.08301831133032973\n",
            "Error:0.006467054957103672\n",
            "Error:0.0003292669000750735\n",
            "Error:1.5055622665134864e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hdrRYZldPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a6547e-fcc6-49e0-e768-5b8c3fc6becd"
      },
      "source": [
        "import sys, numpy as пр\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()                        # dataset of numbers\n",
        "\n",
        "images, labels = (x_train[0:1000].reshape(1000, 28*28) / 255, y_train[0:1000])  # reshape df first 1000 imgs to imgs 28*28, labels are first 1000 from y_train\n",
        "one_hot_labels = np.zeros((len(labels), 10))\n",
        "\n",
        "for i, l in enumerate(labels):\n",
        "    one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images = x_test.reshape(len(x_test), 28*28) / 255\n",
        "test_labels = np.zeros((len(y_test), 10))\n",
        "\n",
        "for i, l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1\n",
        "\n",
        "np.random.seed(1)\n",
        "relu = lambda x:(x >= 0) * x\n",
        "relu2deriv = lambda x: x >= 0 \n",
        "\n",
        "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
        "weights_0_1 = 0.2 * np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2 * np.random.random((hidden_size,num_labels)) - 0.1\n",
        "\n",
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0, 0)\n",
        "    for i in range(len(images)):\n",
        "        layer_0 = images[i:i+1]\n",
        "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)\n",
        "\n",
        "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
        "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
        "        \n",
        "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "    sys.stdout.write(\"\\r\"+ \\\n",
        "                     \" I:\"+str(j)+ \\\n",
        "                     \" Error:\" + str(error/float(len(images)))[0:5] +\\\n",
        "                     \" Correct:\" + str(correct_cnt/float(len(images))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I:349 Error:0.108 Correct:1.0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwTIVowCVClu",
        "outputId": "f6fd4f15-845e-408c-fbf2-dfae7ce89c1c"
      },
      "source": [
        "if(j % 10 == 0 or j == iterations - 1):\n",
        "    error, correct_cnt = (0.0, 0)\n",
        "\n",
        "    for i in range(len(test_images)):\n",
        "\n",
        "        layer_0 = test_images[i:i+1]\n",
        "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)\n",
        "\n",
        "        error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "        correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "\n",
        "sys.stdout.write(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] + \" Test-Acc:\" + str(correct_cnt/float(len(test_images))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Test-Err:0.653 Test-Acc:0.7073"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txxzDcBqY-D2"
      },
      "source": [
        "**Регуляризация** — это подмножество методов, способствующих обобщению\n",
        "изучаемых моделей, часто за счет препятствования изучению мелких деталей.\n",
        "\n",
        "### Стандартный способ регуляризации: прореживание (дропаут)\n",
        "**Суть метода**: выключение (установка в 0) случайных нейронов в процессе обучения\n",
        "\n",
        "Прореживание заставляет большую сеть действовать подобно маленькой\n",
        "сети, обучая случайно выбираемые подразделы, а маленькие сети не подвержены переобучению, т.к. они не обладают большой выразительной силой и не в состоянии фиксировать\n",
        "мелкие детали (шум), которые, как правило, являются причиной переобучения.\n",
        "\n",
        "Начальное состояние нейронных сетей всегда выбирается случайно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbPDppx0WxaH",
        "outputId": "71abc0ab-969f-4f25-bcba-e7a4c683b6ef"
      },
      "source": [
        "import numpy, sys\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "def relu(x):\n",
        "    return (x >= 0) * x     # Возвращает x, если x>0; иначе возвращает О\n",
        "\n",
        "def relu2deriv(output):\n",
        "    return output >= 0      # Возвращает 1, если output > 0; иначе возвращаете\n",
        "\n",
        "alpha, iterations, hidden_size = (0.005, 300, 100)\n",
        "pixels_per_image, num_labels = (784, 10)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1\n",
        "\n",
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0, 0)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        layer_0 = images[i:i+1]\n",
        "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "\n",
        "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
        "\n",
        "        layer_1 *= dropout_mask * 2\n",
        "        layer_2 = np.dot(layer_1,weights_1_2)\n",
        "\n",
        "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
        "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
        "        \n",
        "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "        layer_1_delta *= dropout_mask\n",
        "\n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "    if (j % 10 == 0):\n",
        "        test_error = 0.0\n",
        "        test_correct_cnt = 0\n",
        "        for i in range(len(test_images)):\n",
        "            layer_0 = test_images[i:i+1]\n",
        "            layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "            layer_2 = np.dot(layer_1, weights_1_2)\n",
        "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "            test_correct_cnt += int(np.argmax(layer_2) == \\\n",
        "            np.argmax(test_labels[i:i+1]))\n",
        "        sys.stdout.write(\"\\n\" + \\\n",
        "        \"I:\" + str(j) + \\\n",
        "        \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
        "        \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
        "        \" Train-Err:\" + str(error/ float(len(images)))[0:5] +\\\n",
        "        \" Train-Acc:\" + str(correct_cnt/ float(len(images))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I:0 Test-Err:0.641 Test-Acc:0.6333 Train-Err:0.891 Train-Acc:0.413\n",
            "I:10 Test-Err:0.458 Test-Acc:0.787 Train-Err:0.472 Train-Acc:0.764\n",
            "I:20 Test-Err:0.415 Test-Acc:0.8133 Train-Err:0.430 Train-Acc:0.809\n",
            "I:30 Test-Err:0.421 Test-Acc:0.8114 Train-Err:0.415 Train-Acc:0.811\n",
            "I:40 Test-Err:0.419 Test-Acc:0.8112 Train-Err:0.413 Train-Acc:0.827\n",
            "I:50 Test-Err:0.409 Test-Acc:0.8133 Train-Err:0.392 Train-Acc:0.836\n",
            "I:60 Test-Err:0.412 Test-Acc:0.8236 Train-Err:0.402 Train-Acc:0.836\n",
            "I:70 Test-Err:0.412 Test-Acc:0.8033 Train-Err:0.383 Train-Acc:0.857\n",
            "I:80 Test-Err:0.410 Test-Acc:0.8054 Train-Err:0.386 Train-Acc:0.854\n",
            "I:90 Test-Err:0.411 Test-Acc:0.8144 Train-Err:0.376 Train-Acc:0.868\n",
            "I:100 Test-Err:0.411 Test-Acc:0.7903 Train-Err:0.369 Train-Acc:0.864\n",
            "I:110 Test-Err:0.411 Test-Acc:0.8003 Train-Err:0.371 Train-Acc:0.868\n",
            "I:120 Test-Err:0.402 Test-Acc:0.8046 Train-Err:0.353 Train-Acc:0.857\n",
            "I:130 Test-Err:0.408 Test-Acc:0.8091 Train-Err:0.352 Train-Acc:0.867\n",
            "I:140 Test-Err:0.405 Test-Acc:0.8083 Train-Err:0.355 Train-Acc:0.885\n",
            "I:150 Test-Err:0.404 Test-Acc:0.8107 Train-Err:0.342 Train-Acc:0.883\n",
            "I:160 Test-Err:0.399 Test-Acc:0.8146 Train-Err:0.361 Train-Acc:0.876\n",
            "I:170 Test-Err:0.404 Test-Acc:0.8074 Train-Err:0.344 Train-Acc:0.889\n",
            "I:180 Test-Err:0.399 Test-Acc:0.807 Train-Err:0.333 Train-Acc:0.892\n",
            "I:190 Test-Err:0.407 Test-Acc:0.8066 Train-Err:0.335 Train-Acc:0.898\n",
            "I:200 Test-Err:0.405 Test-Acc:0.8036 Train-Err:0.347 Train-Acc:0.893\n",
            "I:210 Test-Err:0.405 Test-Acc:0.8034 Train-Err:0.336 Train-Acc:0.894\n",
            "I:220 Test-Err:0.402 Test-Acc:0.8067 Train-Err:0.325 Train-Acc:0.896\n",
            "I:230 Test-Err:0.404 Test-Acc:0.8091 Train-Err:0.321 Train-Acc:0.894\n",
            "I:240 Test-Err:0.415 Test-Acc:0.8091 Train-Err:0.332 Train-Acc:0.898\n",
            "I:250 Test-Err:0.395 Test-Acc:0.8182 Train-Err:0.320 Train-Acc:0.899\n",
            "I:260 Test-Err:0.390 Test-Acc:0.8204 Train-Err:0.321 Train-Acc:0.899\n",
            "I:270 Test-Err:0.382 Test-Acc:0.8194 Train-Err:0.312 Train-Acc:0.906\n",
            "I:280 Test-Err:0.396 Test-Acc:0.8208 Train-Err:0.317 Train-Acc:0.9\n",
            "I:290 Test-Err:0.399 Test-Acc:0.8181 Train-Err:0.301 Train-Acc:0.908"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SibPy9_Wxce",
        "outputId": "37bdaf2b-d744-4dc2-8d53-d1a01ef23d90"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "def relu(x):\n",
        "    return (x >= 0) * x     # Возвращает x, если x > 0\n",
        "\n",
        "def relu2deriv(output):\n",
        "    return output >= 0      # Возвращает 1, если output >0\n",
        "\n",
        "batch_size = 100\n",
        "alpha, iterations = (0.001, 300)\n",
        "pixels_per_image, num_labels, hidden_size = (784, 10, 100)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
        "\n",
        "for j in range(iterations):\n",
        "    error, correct_cnt = (0.0, 0)\n",
        "\n",
        "    for i in range(int(len(images) / batch_size)):\n",
        "        batch_start, batch_end = ((i * batch_size),((i+1) * batch_size))\n",
        "        \n",
        "        layer_0 = images[batch_start:batch_end]\n",
        "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "        \n",
        "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
        "        \n",
        "        layer_1 *= dropout_mask * 2\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)\n",
        "        \n",
        "        error += np.sum((labels[batch_start:batch_end] - layer_2) ** 2)\n",
        "        \n",
        "        for k in range(batch_size):\n",
        "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
        "            \n",
        "            layer_2_delta = (labels[batch_start:batch_end]-layer_2) / batch_size\n",
        "            layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "            layer_1_delta *= dropout_mask\n",
        "            \n",
        "            weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "            weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "    \n",
        "    if(j%10 == 0):\n",
        "        test_error = 0.0\n",
        "        test_correct_cnt = 0\n",
        "        \n",
        "        for i in range(len(test_images)):\n",
        "            layer_0 = test_images[i:i+1]\n",
        "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "            layer_2 = np.dot(layer_1, weights_1_2)\n",
        "\n",
        "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "            test_correct_cnt += int(np.argmax(layer_2) == \\\n",
        "            np.argmax(test_labels[i:i+1]))\n",
        "        sys.stdout.write(\"\\n\" + \\\n",
        "        \"I:\" + str(j) + \\\n",
        "        \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
        "        \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
        "        \" Train-Err:\" + str(error/ float(len(images)))[0:5] +\\\n",
        "        \" Train-Acc:\" + str(correct_cnt/ float(len(images))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I:0 Test-Err:0.815 Test-Acc:0.3832 Train-Err:1.284 Train-Acc:0.165\n",
            "I:10 Test-Err:0.568 Test-Acc:0.7173 Train-Err:0.591 Train-Acc:0.672\n",
            "I:20 Test-Err:0.510 Test-Acc:0.7571 Train-Err:0.532 Train-Acc:0.729\n",
            "I:30 Test-Err:0.485 Test-Acc:0.7793 Train-Err:0.498 Train-Acc:0.754\n",
            "I:40 Test-Err:0.468 Test-Acc:0.7877 Train-Err:0.489 Train-Acc:0.749\n",
            "I:50 Test-Err:0.458 Test-Acc:0.793 Train-Err:0.468 Train-Acc:0.775\n",
            "I:60 Test-Err:0.452 Test-Acc:0.7995 Train-Err:0.452 Train-Acc:0.799\n",
            "I:70 Test-Err:0.446 Test-Acc:0.803 Train-Err:0.453 Train-Acc:0.792\n",
            "I:80 Test-Err:0.451 Test-Acc:0.7968 Train-Err:0.457 Train-Acc:0.786\n",
            "I:90 Test-Err:0.447 Test-Acc:0.795 Train-Err:0.454 Train-Acc:0.799\n",
            "I:100 Test-Err:0.448 Test-Acc:0.793 Train-Err:0.447 Train-Acc:0.796\n",
            "I:110 Test-Err:0.441 Test-Acc:0.7943 Train-Err:0.426 Train-Acc:0.816\n",
            "I:120 Test-Err:0.442 Test-Acc:0.7966 Train-Err:0.431 Train-Acc:0.813\n",
            "I:130 Test-Err:0.441 Test-Acc:0.7906 Train-Err:0.434 Train-Acc:0.816\n",
            "I:140 Test-Err:0.447 Test-Acc:0.7874 Train-Err:0.437 Train-Acc:0.822\n",
            "I:150 Test-Err:0.443 Test-Acc:0.7899 Train-Err:0.414 Train-Acc:0.823\n",
            "I:160 Test-Err:0.438 Test-Acc:0.797 Train-Err:0.427 Train-Acc:0.811\n",
            "I:170 Test-Err:0.440 Test-Acc:0.7884 Train-Err:0.418 Train-Acc:0.828\n",
            "I:180 Test-Err:0.436 Test-Acc:0.7935 Train-Err:0.407 Train-Acc:0.834\n",
            "I:190 Test-Err:0.434 Test-Acc:0.7935 Train-Err:0.410 Train-Acc:0.831\n",
            "I:200 Test-Err:0.435 Test-Acc:0.7972 Train-Err:0.416 Train-Acc:0.829\n",
            "I:210 Test-Err:0.434 Test-Acc:0.7923 Train-Err:0.409 Train-Acc:0.83\n",
            "I:220 Test-Err:0.433 Test-Acc:0.8032 Train-Err:0.396 Train-Acc:0.832\n",
            "I:230 Test-Err:0.431 Test-Acc:0.8036 Train-Err:0.393 Train-Acc:0.853\n",
            "I:240 Test-Err:0.430 Test-Acc:0.8047 Train-Err:0.397 Train-Acc:0.844\n",
            "I:250 Test-Err:0.429 Test-Acc:0.8028 Train-Err:0.386 Train-Acc:0.843\n",
            "I:260 Test-Err:0.431 Test-Acc:0.8038 Train-Err:0.394 Train-Acc:0.843\n",
            "I:270 Test-Err:0.428 Test-Acc:0.8014 Train-Err:0.384 Train-Acc:0.845\n",
            "I:280 Test-Err:0.430 Test-Acc:0.8067 Train-Err:0.401 Train-Acc:0.846\n",
            "I:290 Test-Err:0.428 Test-Acc:0.7975 Train-Err:0.383 Train-Acc:0.851"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQm0Ey2GjJgt"
      },
      "source": [
        "Разновидности выходных слоёв:\n",
        "- прогноз — простые числовые значения(без функции активации). Главное здесь обеспечить такую нелинейность в выходном слое, чтобы можно было получить достоверный прогноз.\n",
        "- прогноз — независимые ответы да/нет. В таких случаях лучше всего использовать функцию активации sigmoid, потому\n",
        "что она моделирует вероятности для каждого узла независимо.\n",
        "- прогноз — выбор одного варианта\n",
        "из нескольких (softmax). Самый распространенный вариант использования нейронных сетей — прогнозирование\n",
        "выбора одной метки из нескольких."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCHFANu-WxgK",
        "outputId": "0f567b4e-8d10-4b80-bbf5-00202eb5c98b"
      },
      "source": [
        "import numpy as np, sys\n",
        "from keras.datasets import mnist\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
        "\n",
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "for i, l in enumerate(labels):\n",
        "    one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images = x_test.reshape(len(x_test), 28*28) / 255\n",
        "test_labels = np.zeros((len(y_test), 10))\n",
        "for i, l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh2deriv(output):\n",
        "    return 1 - (output ** 2)\n",
        "\n",
        "def softmax(x):\n",
        "    temp = np.exp(x)\n",
        "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
        "\n",
        "alpha, iterations, hidden_size = (2, 300, 100)\n",
        "pixels_per_image, num_labels = (784, 10)\n",
        "batch_size = 100\n",
        "\n",
        "weights_0_1 = 0.02 * np.random.random((pixels_per_image, hidden_size)) - 0.01\n",
        "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1\n",
        "\n",
        "for j in range(iterations):\n",
        "    correct_cnt = 0\n",
        "    for i in range(int(len(images) / batch_size)):\n",
        "        batch_start, batch_end = ((i * batch_size), ((i+1)*batch_size))\n",
        "        \n",
        "        layer_0 = images[batch_start:batch_end]\n",
        "        layer_1 = tanh(np.dot(layer_0, weights_0_1))\n",
        "        \n",
        "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
        "        \n",
        "        layer_1 *= dropout_mask * 2\n",
        "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
        "        \n",
        "        for k in range(batch_size):\n",
        "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
        "        \n",
        "        layer_2_delta = (labels[batch_start:batch_end]-layer_2) / (batch_size * layer_2.shape[0])\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1)\n",
        "        layer_1_delta *= dropout_mask\n",
        "        \n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "    \n",
        "    test_correct_cnt = 0\n",
        "\n",
        "    for i in range(len(test_images)):\n",
        "        layer_0 = test_images[i:i+1]\n",
        "        layer_1 = tanh(np.dot(layer_0, weights_0_1))\n",
        "        layer_2 = np.dot(layer_1, weights_1_2)\n",
        "        test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "\n",
        "    if(j % 10 == 0):\n",
        "        sys.stdout.write(\"\\n\"+ \"I:\" + str(j) + \\\n",
        "        \" Test-Acc:\"+ str(test_correct_cnt/float(len(test_images)))+\\\n",
        "        \" Train-Acc:\" + str(correct_cnt/float(len(images))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I:0 Test-Acc:0.394 Train-Acc:0.156\n",
            "I:10 Test-Acc:0.6867 Train-Acc:0.723\n",
            "I:20 Test-Acc:0.7025 Train-Acc:0.732\n",
            "I:30 Test-Acc:0.734 Train-Acc:0.763\n",
            "I:40 Test-Acc:0.7663 Train-Acc:0.794\n",
            "I:50 Test-Acc:0.7913 Train-Acc:0.819\n",
            "I:60 Test-Acc:0.8102 Train-Acc:0.849\n",
            "I:70 Test-Acc:0.8228 Train-Acc:0.864\n",
            "I:80 Test-Acc:0.831 Train-Acc:0.867\n",
            "I:90 Test-Acc:0.8364 Train-Acc:0.885\n",
            "I:100 Test-Acc:0.8407 Train-Acc:0.883\n",
            "I:110 Test-Acc:0.845 Train-Acc:0.891\n",
            "I:120 Test-Acc:0.8481 Train-Acc:0.901\n",
            "I:130 Test-Acc:0.8505 Train-Acc:0.901\n",
            "I:140 Test-Acc:0.8526 Train-Acc:0.905\n",
            "I:150 Test-Acc:0.8555 Train-Acc:0.914\n",
            "I:160 Test-Acc:0.8577 Train-Acc:0.925\n",
            "I:170 Test-Acc:0.8596 Train-Acc:0.918\n",
            "I:180 Test-Acc:0.8619 Train-Acc:0.933\n",
            "I:190 Test-Acc:0.863 Train-Acc:0.933\n",
            "I:200 Test-Acc:0.8642 Train-Acc:0.926\n",
            "I:210 Test-Acc:0.8653 Train-Acc:0.931\n",
            "I:220 Test-Acc:0.8668 Train-Acc:0.93\n",
            "I:230 Test-Acc:0.8672 Train-Acc:0.937\n",
            "I:240 Test-Acc:0.8681 Train-Acc:0.938\n",
            "I:250 Test-Acc:0.8687 Train-Acc:0.937\n",
            "I:260 Test-Acc:0.8684 Train-Acc:0.945\n",
            "I:270 Test-Acc:0.8703 Train-Acc:0.951\n",
            "I:280 Test-Acc:0.8699 Train-Acc:0.949\n",
            "I:290 Test-Acc:0.8701 Train-Acc:0.94"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H49S6HjCN9cy",
        "outputId": "54706e80-2ef2-4916-d599-95c3759edbf5"
      },
      "source": [
        "import numpy as np, sys\n",
        "from keras.datasets import mnist\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "images, labels = (x_train[0:1000].reshape(1000, 28*28) / 255, y_train[0:1000])\n",
        "\n",
        "one_hot_labels = np.zeros((len(labels), 10))\n",
        "\n",
        "for i,l in enumerate(labels):\n",
        "    one_hot_labels[i][l] = 1\n",
        "\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images = x_test.reshape(len(x_test), 28*28) / 255\n",
        "test_labels = np.zeros((len(y_test), 10))\n",
        "\n",
        "for i, l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh2deriv(output):\n",
        "    return 1 - (output ** 2)\n",
        "\n",
        "def softmax(x):\n",
        "    temp = np.exp(x)\n",
        "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
        "\n",
        "alpha, iterations = (2, 300)\n",
        "pixels_per_image, num_labels = (784, 10)\n",
        "\n",
        "batch_size = 128\n",
        "input_rows = 28\n",
        "input_cols = 28\n",
        "\n",
        "kernel_rows = 3\n",
        "kernel_cols = 3\n",
        "num_kernels = 16\n",
        "\n",
        "hidden_size = ((input_rows - kernel_rows) * (input_cols - kernel_cols)) * num_kernels\n",
        "kernels = 0.02 * np.random.random((kernel_rows*kernel_cols, num_kernels)) - 0.01\n",
        "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1\n",
        "\n",
        "def get_image_section(layer,row_from, row_to, col_from, col_to):\n",
        "    section = layer[:, row_from:row_to, col_from:col_to]\n",
        "    return section.reshape(-1, 1, row_to - row_from, col_to - col_from)\n",
        "\n",
        "for j in range(iterations):\n",
        "    correct_cnt = 0\n",
        "    for i in range(int(len(images) / batch_size)):\n",
        "        batch_start, batch_end=((i * batch_size),((i+1)*batch_size))\n",
        "        layer_0 = images[batch_start:batch_end]\n",
        "        layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28)\n",
        "        layer_0.shape\n",
        "        sects = list()\n",
        "        for row_start in range(layer_0.shape[1]-kernel_rows):\n",
        "            for col_start in range(layer_0.shape[2] - kernel_cols):\n",
        "                sect = get_image_section(\n",
        "                    layer_0,\n",
        "                    row_start,\n",
        "                    row_start + kernel_rows,\n",
        "                    col_start,\n",
        "                    col_start + kernel_cols\n",
        "                )\n",
        "                sects.append(sect)\n",
        "\n",
        "        expanded_input = np.concatenate(sects,axis=1)\n",
        "        es = expanded_input.shape\n",
        "        flattened_input = expanded_input.reshape(es[0]*es[1],-1)\n",
        "        \n",
        "        kernel_output = flattened_input.dot(kernels)\n",
        "        layer_1 = tanh(kernel_output.reshape(es[0],-1))\n",
        "        \n",
        "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
        "        \n",
        "        layer_1 *= dropout_mask * 2\n",
        "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
        "        \n",
        "        for k in range(batch_size):\n",
        "            labelset = labels[batch_start+k:batch_start+k+1]\n",
        "            _inc = int(np.argmax(layer_2[k:k+1]) == np.argmax(labelset))\n",
        "            correct_cnt += _inc\n",
        "\n",
        "        layer_2_delta = (labels[batch_start:batch_end] - layer_2) / (batch_size * layer_2.shape[0])\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1)\n",
        "        layer_1_delta *= dropout_mask\n",
        "        \n",
        "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "        l1d_reshape = layer_1_delta.reshape(kernel_output.shape)\n",
        "        k_update = flattened_input.T.dot(l1d_reshape)\n",
        "        kernels -= alpha * k_update\n",
        "\n",
        "    test_correct_cnt = 0\n",
        "    \n",
        "    for i in range(len(test_images)):\n",
        "        layer_0 = test_images[i:i+1]\n",
        "        layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28)\n",
        "        layer_0.shape\n",
        "        \n",
        "        sects = list()\n",
        "        \n",
        "        for row_start in range(layer_0.shape[1]-kernel_rows):\n",
        "            for col_start in range(layer_0.shape[2] - kernel_cols):\n",
        "                sect = get_image_section(\n",
        "                    layer_0,\n",
        "                    row_start,\n",
        "                    row_start + kernel_rows,\n",
        "                    col_start,\n",
        "                    col_start + kernel_cols\n",
        "                )\n",
        "                sects.append(sect)\n",
        "\n",
        "        expanded_input = np.concatenate(sects,axis=1)\n",
        "        es = expanded_input.shape\n",
        "        flattened_input = expanded_input.reshape( es[0]*es[1], -1)\n",
        "        \n",
        "        kernel_output = flattened_input.dot(kernels)\n",
        "        layer_1 = tanh(kernel_output.reshape(es[0], -1))\n",
        "        layer_2 = np.dot(layer_1,weights_1_2)\n",
        "        \n",
        "        test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "    \n",
        "    if(j % 1 == 0):\n",
        "        sys.stdout.write(\"\\n\"+ \\\n",
        "        \"I:\" + str(j) + \\\n",
        "        \" Test-Acc:\"+str(test_correct_cnt/float(len(test_images)))+ \\\n",
        "        \" Train-Acc:\" + str(correct_cnt/float(len(images))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I:0 Test-Acc:0.0288 Train-Acc:0.055\n",
            "I:1 Test-Acc:0.0273 Train-Acc:0.037\n",
            "I:2 Test-Acc:0.028 Train-Acc:0.037\n",
            "I:3 Test-Acc:0.0292 Train-Acc:0.04\n",
            "I:4 Test-Acc:0.0339 Train-Acc:0.046\n",
            "I:5 Test-Acc:0.0478 Train-Acc:0.068\n",
            "I:6 Test-Acc:0.076 Train-Acc:0.083\n",
            "I:7 Test-Acc:0.1316 Train-Acc:0.096\n",
            "I:8 Test-Acc:0.2137 Train-Acc:0.127\n",
            "I:9 Test-Acc:0.2941 Train-Acc:0.148\n",
            "I:10 Test-Acc:0.3563 Train-Acc:0.181\n",
            "I:11 Test-Acc:0.4023 Train-Acc:0.209\n",
            "I:12 Test-Acc:0.4358 Train-Acc:0.238\n",
            "I:13 Test-Acc:0.4473 Train-Acc:0.286\n",
            "I:14 Test-Acc:0.4389 Train-Acc:0.274\n",
            "I:15 Test-Acc:0.3951 Train-Acc:0.257\n",
            "I:16 Test-Acc:0.2222 Train-Acc:0.243\n",
            "I:17 Test-Acc:0.0613 Train-Acc:0.112\n",
            "I:18 Test-Acc:0.0266 Train-Acc:0.035\n",
            "I:19 Test-Acc:0.0127 Train-Acc:0.026\n",
            "I:20 Test-Acc:0.0133 Train-Acc:0.022\n",
            "I:21 Test-Acc:0.0185 Train-Acc:0.038\n",
            "I:22 Test-Acc:0.0363 Train-Acc:0.038\n",
            "I:23 Test-Acc:0.0928 Train-Acc:0.067\n",
            "I:24 Test-Acc:0.1994 Train-Acc:0.081\n",
            "I:25 Test-Acc:0.3086 Train-Acc:0.154\n",
            "I:26 Test-Acc:0.4276 Train-Acc:0.204\n",
            "I:27 Test-Acc:0.5323 Train-Acc:0.256\n",
            "I:28 Test-Acc:0.5919 Train-Acc:0.305\n",
            "I:29 Test-Acc:0.6324 Train-Acc:0.341\n",
            "I:30 Test-Acc:0.6608 Train-Acc:0.426\n",
            "I:31 Test-Acc:0.6815 Train-Acc:0.439\n",
            "I:32 Test-Acc:0.7048 Train-Acc:0.462\n",
            "I:33 Test-Acc:0.7171 Train-Acc:0.484\n",
            "I:34 Test-Acc:0.7313 Train-Acc:0.505\n",
            "I:35 Test-Acc:0.7355 Train-Acc:0.53\n",
            "I:36 Test-Acc:0.7417 Train-Acc:0.548\n",
            "I:37 Test-Acc:0.747 Train-Acc:0.534\n",
            "I:38 Test-Acc:0.7491 Train-Acc:0.55\n",
            "I:39 Test-Acc:0.7459 Train-Acc:0.562\n",
            "I:40 Test-Acc:0.7352 Train-Acc:0.54\n",
            "I:41 Test-Acc:0.7082 Train-Acc:0.496\n",
            "I:42 Test-Acc:0.6487 Train-Acc:0.456\n",
            "I:43 Test-Acc:0.5209 Train-Acc:0.353\n",
            "I:44 Test-Acc:0.3305 Train-Acc:0.234\n",
            "I:45 Test-Acc:0.2052 Train-Acc:0.174\n",
            "I:46 Test-Acc:0.2149 Train-Acc:0.136\n",
            "I:47 Test-Acc:0.2679 Train-Acc:0.171\n",
            "I:48 Test-Acc:0.3237 Train-Acc:0.172\n",
            "I:49 Test-Acc:0.3581 Train-Acc:0.186\n",
            "I:50 Test-Acc:0.4202 Train-Acc:0.21\n",
            "I:51 Test-Acc:0.5165 Train-Acc:0.223\n",
            "I:52 Test-Acc:0.6007 Train-Acc:0.262\n",
            "I:53 Test-Acc:0.6476 Train-Acc:0.308\n",
            "I:54 Test-Acc:0.676 Train-Acc:0.363\n",
            "I:55 Test-Acc:0.696 Train-Acc:0.402\n",
            "I:56 Test-Acc:0.7077 Train-Acc:0.434\n",
            "I:57 Test-Acc:0.7204 Train-Acc:0.441\n",
            "I:58 Test-Acc:0.7303 Train-Acc:0.475\n",
            "I:59 Test-Acc:0.7359 Train-Acc:0.475\n",
            "I:60 Test-Acc:0.7401 Train-Acc:0.525\n",
            "I:61 Test-Acc:0.7493 Train-Acc:0.517\n",
            "I:62 Test-Acc:0.7533 Train-Acc:0.517\n",
            "I:63 Test-Acc:0.7606 Train-Acc:0.538\n",
            "I:64 Test-Acc:0.7644 Train-Acc:0.554\n",
            "I:65 Test-Acc:0.7724 Train-Acc:0.57\n",
            "I:66 Test-Acc:0.7788 Train-Acc:0.586\n",
            "I:67 Test-Acc:0.7855 Train-Acc:0.595\n",
            "I:68 Test-Acc:0.7853 Train-Acc:0.591\n",
            "I:69 Test-Acc:0.7925 Train-Acc:0.605\n",
            "I:70 Test-Acc:0.7973 Train-Acc:0.64\n",
            "I:71 Test-Acc:0.8013 Train-Acc:0.621\n",
            "I:72 Test-Acc:0.8029 Train-Acc:0.626\n",
            "I:73 Test-Acc:0.8092 Train-Acc:0.631\n",
            "I:74 Test-Acc:0.8099 Train-Acc:0.638\n",
            "I:75 Test-Acc:0.8156 Train-Acc:0.661\n",
            "I:76 Test-Acc:0.8156 Train-Acc:0.639\n",
            "I:77 Test-Acc:0.8184 Train-Acc:0.65\n",
            "I:78 Test-Acc:0.8216 Train-Acc:0.67\n",
            "I:79 Test-Acc:0.8246 Train-Acc:0.675\n",
            "I:80 Test-Acc:0.8237 Train-Acc:0.666\n",
            "I:81 Test-Acc:0.8273 Train-Acc:0.673\n",
            "I:82 Test-Acc:0.8273 Train-Acc:0.704\n",
            "I:83 Test-Acc:0.8314 Train-Acc:0.674\n",
            "I:84 Test-Acc:0.8292 Train-Acc:0.686\n",
            "I:85 Test-Acc:0.8335 Train-Acc:0.699\n",
            "I:86 Test-Acc:0.8359 Train-Acc:0.694\n",
            "I:87 Test-Acc:0.8375 Train-Acc:0.704\n",
            "I:88 Test-Acc:0.8373 Train-Acc:0.697\n",
            "I:89 Test-Acc:0.8398 Train-Acc:0.704\n",
            "I:90 Test-Acc:0.8393 Train-Acc:0.687\n",
            "I:91 Test-Acc:0.8436 Train-Acc:0.705\n",
            "I:92 Test-Acc:0.8437 Train-Acc:0.711\n",
            "I:93 Test-Acc:0.8446 Train-Acc:0.721\n",
            "I:94 Test-Acc:0.845 Train-Acc:0.719\n",
            "I:95 Test-Acc:0.8469 Train-Acc:0.724\n",
            "I:96 Test-Acc:0.8476 Train-Acc:0.726\n",
            "I:97 Test-Acc:0.848 Train-Acc:0.718\n",
            "I:98 Test-Acc:0.8496 Train-Acc:0.719\n",
            "I:99 Test-Acc:0.85 Train-Acc:0.73\n",
            "I:100 Test-Acc:0.8511 Train-Acc:0.737\n",
            "I:101 Test-Acc:0.8503 Train-Acc:0.73\n",
            "I:102 Test-Acc:0.8504 Train-Acc:0.717\n",
            "I:103 Test-Acc:0.8528 Train-Acc:0.74\n",
            "I:104 Test-Acc:0.8532 Train-Acc:0.733\n",
            "I:105 Test-Acc:0.8537 Train-Acc:0.73\n",
            "I:106 Test-Acc:0.8568 Train-Acc:0.721\n",
            "I:107 Test-Acc:0.857 Train-Acc:0.75\n",
            "I:108 Test-Acc:0.8558 Train-Acc:0.731\n",
            "I:109 Test-Acc:0.8578 Train-Acc:0.744\n",
            "I:110 Test-Acc:0.8588 Train-Acc:0.754\n",
            "I:111 Test-Acc:0.8579 Train-Acc:0.732\n",
            "I:112 Test-Acc:0.8582 Train-Acc:0.747\n",
            "I:113 Test-Acc:0.8593 Train-Acc:0.747\n",
            "I:114 Test-Acc:0.8598 Train-Acc:0.751\n",
            "I:115 Test-Acc:0.8603 Train-Acc:0.74\n",
            "I:116 Test-Acc:0.86 Train-Acc:0.753\n",
            "I:117 Test-Acc:0.8588 Train-Acc:0.746\n",
            "I:118 Test-Acc:0.861 Train-Acc:0.741\n",
            "I:119 Test-Acc:0.8616 Train-Acc:0.731\n",
            "I:120 Test-Acc:0.8629 Train-Acc:0.753\n",
            "I:121 Test-Acc:0.8609 Train-Acc:0.743\n",
            "I:122 Test-Acc:0.8627 Train-Acc:0.752\n",
            "I:123 Test-Acc:0.8646 Train-Acc:0.76\n",
            "I:124 Test-Acc:0.8649 Train-Acc:0.766\n",
            "I:125 Test-Acc:0.8659 Train-Acc:0.752\n",
            "I:126 Test-Acc:0.868 Train-Acc:0.756\n",
            "I:127 Test-Acc:0.8648 Train-Acc:0.767\n",
            "I:128 Test-Acc:0.8662 Train-Acc:0.747\n",
            "I:129 Test-Acc:0.8669 Train-Acc:0.753\n",
            "I:130 Test-Acc:0.8694 Train-Acc:0.753\n",
            "I:131 Test-Acc:0.8692 Train-Acc:0.76\n",
            "I:132 Test-Acc:0.8658 Train-Acc:0.756\n",
            "I:133 Test-Acc:0.8666 Train-Acc:0.769\n",
            "I:134 Test-Acc:0.8692 Train-Acc:0.77\n",
            "I:135 Test-Acc:0.8681 Train-Acc:0.757\n",
            "I:136 Test-Acc:0.8705 Train-Acc:0.77\n",
            "I:137 Test-Acc:0.8706 Train-Acc:0.77\n",
            "I:138 Test-Acc:0.8684 Train-Acc:0.768\n",
            "I:139 Test-Acc:0.8664 Train-Acc:0.774\n",
            "I:140 Test-Acc:0.8666 Train-Acc:0.756\n",
            "I:141 Test-Acc:0.8705 Train-Acc:0.783\n",
            "I:142 Test-Acc:0.87 Train-Acc:0.775\n",
            "I:143 Test-Acc:0.8729 Train-Acc:0.769\n",
            "I:144 Test-Acc:0.8725 Train-Acc:0.776\n",
            "I:145 Test-Acc:0.8721 Train-Acc:0.772\n",
            "I:146 Test-Acc:0.8718 Train-Acc:0.765\n",
            "I:147 Test-Acc:0.8746 Train-Acc:0.777\n",
            "I:148 Test-Acc:0.8746 Train-Acc:0.77\n",
            "I:149 Test-Acc:0.8734 Train-Acc:0.778\n",
            "I:150 Test-Acc:0.873 Train-Acc:0.785\n",
            "I:151 Test-Acc:0.8732 Train-Acc:0.76\n",
            "I:152 Test-Acc:0.8727 Train-Acc:0.779\n",
            "I:153 Test-Acc:0.8754 Train-Acc:0.772\n",
            "I:154 Test-Acc:0.8729 Train-Acc:0.773\n",
            "I:155 Test-Acc:0.8758 Train-Acc:0.784\n",
            "I:156 Test-Acc:0.8732 Train-Acc:0.774\n",
            "I:157 Test-Acc:0.8743 Train-Acc:0.782\n",
            "I:158 Test-Acc:0.8762 Train-Acc:0.772\n",
            "I:159 Test-Acc:0.8755 Train-Acc:0.79\n",
            "I:160 Test-Acc:0.8751 Train-Acc:0.774\n",
            "I:161 Test-Acc:0.8749 Train-Acc:0.782\n",
            "I:162 Test-Acc:0.8744 Train-Acc:0.78\n",
            "I:163 Test-Acc:0.8765 Train-Acc:0.782\n",
            "I:164 Test-Acc:0.8738 Train-Acc:0.796\n",
            "I:165 Test-Acc:0.8753 Train-Acc:0.798\n",
            "I:166 Test-Acc:0.8767 Train-Acc:0.794\n",
            "I:167 Test-Acc:0.8746 Train-Acc:0.784\n",
            "I:168 Test-Acc:0.8769 Train-Acc:0.796\n",
            "I:169 Test-Acc:0.8758 Train-Acc:0.789\n",
            "I:170 Test-Acc:0.8764 Train-Acc:0.79\n",
            "I:171 Test-Acc:0.873 Train-Acc:0.791\n",
            "I:172 Test-Acc:0.8765 Train-Acc:0.797\n",
            "I:173 Test-Acc:0.8772 Train-Acc:0.789\n",
            "I:174 Test-Acc:0.8778 Train-Acc:0.781\n",
            "I:175 Test-Acc:0.8758 Train-Acc:0.799\n",
            "I:176 Test-Acc:0.8773 Train-Acc:0.785\n",
            "I:177 Test-Acc:0.8766 Train-Acc:0.796\n",
            "I:178 Test-Acc:0.8782 Train-Acc:0.803\n",
            "I:179 Test-Acc:0.8789 Train-Acc:0.794\n",
            "I:180 Test-Acc:0.8778 Train-Acc:0.794\n",
            "I:181 Test-Acc:0.8778 Train-Acc:0.8\n",
            "I:182 Test-Acc:0.8785 Train-Acc:0.791\n",
            "I:183 Test-Acc:0.8777 Train-Acc:0.787\n",
            "I:184 Test-Acc:0.8769 Train-Acc:0.781\n",
            "I:185 Test-Acc:0.8765 Train-Acc:0.786\n",
            "I:186 Test-Acc:0.8765 Train-Acc:0.793\n",
            "I:187 Test-Acc:0.8785 Train-Acc:0.796\n",
            "I:188 Test-Acc:0.879 Train-Acc:0.789\n",
            "I:189 Test-Acc:0.8763 Train-Acc:0.79\n",
            "I:190 Test-Acc:0.8774 Train-Acc:0.787\n",
            "I:191 Test-Acc:0.8766 Train-Acc:0.782\n",
            "I:192 Test-Acc:0.8803 Train-Acc:0.798\n",
            "I:193 Test-Acc:0.8781 Train-Acc:0.789\n",
            "I:194 Test-Acc:0.8795 Train-Acc:0.785\n",
            "I:195 Test-Acc:0.8791 Train-Acc:0.807\n",
            "I:196 Test-Acc:0.8778 Train-Acc:0.796\n",
            "I:197 Test-Acc:0.8783 Train-Acc:0.801\n",
            "I:198 Test-Acc:0.8778 Train-Acc:0.81\n",
            "I:199 Test-Acc:0.8771 Train-Acc:0.784\n",
            "I:200 Test-Acc:0.8776 Train-Acc:0.792\n",
            "I:201 Test-Acc:0.8784 Train-Acc:0.794\n",
            "I:202 Test-Acc:0.8787 Train-Acc:0.795\n",
            "I:203 Test-Acc:0.8803 Train-Acc:0.781\n",
            "I:204 Test-Acc:0.8798 Train-Acc:0.804\n",
            "I:205 Test-Acc:0.8779 Train-Acc:0.779\n",
            "I:206 Test-Acc:0.8788 Train-Acc:0.792\n",
            "I:207 Test-Acc:0.8764 Train-Acc:0.793\n",
            "I:208 Test-Acc:0.8792 Train-Acc:0.792\n",
            "I:209 Test-Acc:0.8798 Train-Acc:0.803\n",
            "I:210 Test-Acc:0.8788 Train-Acc:0.804\n",
            "I:211 Test-Acc:0.8793 Train-Acc:0.797\n",
            "I:212 Test-Acc:0.8764 Train-Acc:0.791\n",
            "I:213 Test-Acc:0.8801 Train-Acc:0.801\n",
            "I:214 Test-Acc:0.8814 Train-Acc:0.799\n",
            "I:215 Test-Acc:0.8806 Train-Acc:0.79\n",
            "I:216 Test-Acc:0.8799 Train-Acc:0.8\n",
            "I:217 Test-Acc:0.8803 Train-Acc:0.802\n",
            "I:218 Test-Acc:0.8782 Train-Acc:0.807\n",
            "I:219 Test-Acc:0.8818 Train-Acc:0.797\n",
            "I:220 Test-Acc:0.8793 Train-Acc:0.799\n",
            "I:221 Test-Acc:0.8789 Train-Acc:0.815\n",
            "I:222 Test-Acc:0.8791 Train-Acc:0.816\n",
            "I:223 Test-Acc:0.8793 Train-Acc:0.809\n",
            "I:224 Test-Acc:0.8814 Train-Acc:0.795\n",
            "I:225 Test-Acc:0.8798 Train-Acc:0.799\n",
            "I:226 Test-Acc:0.8805 Train-Acc:0.806\n",
            "I:227 Test-Acc:0.88 Train-Acc:0.808\n",
            "I:228 Test-Acc:0.8782 Train-Acc:0.801\n",
            "I:229 Test-Acc:0.8802 Train-Acc:0.814\n",
            "I:230 Test-Acc:0.8807 Train-Acc:0.8\n",
            "I:231 Test-Acc:0.8809 Train-Acc:0.798\n",
            "I:232 Test-Acc:0.8805 Train-Acc:0.82\n",
            "I:233 Test-Acc:0.8795 Train-Acc:0.794\n",
            "I:234 Test-Acc:0.8807 Train-Acc:0.806\n",
            "I:235 Test-Acc:0.8806 Train-Acc:0.808\n",
            "I:236 Test-Acc:0.8787 Train-Acc:0.802\n",
            "I:237 Test-Acc:0.8796 Train-Acc:0.81\n",
            "I:238 Test-Acc:0.8766 Train-Acc:0.805\n",
            "I:239 Test-Acc:0.8781 Train-Acc:0.792\n",
            "I:240 Test-Acc:0.8787 Train-Acc:0.809\n",
            "I:241 Test-Acc:0.8762 Train-Acc:0.802\n",
            "I:242 Test-Acc:0.8775 Train-Acc:0.811\n",
            "I:243 Test-Acc:0.8804 Train-Acc:0.814\n",
            "I:244 Test-Acc:0.8794 Train-Acc:0.804\n",
            "I:245 Test-Acc:0.8788 Train-Acc:0.801\n",
            "I:246 Test-Acc:0.8777 Train-Acc:0.795\n",
            "I:247 Test-Acc:0.8785 Train-Acc:0.808\n",
            "I:248 Test-Acc:0.8788 Train-Acc:0.803\n",
            "I:249 Test-Acc:0.8773 Train-Acc:0.813\n",
            "I:250 Test-Acc:0.8786 Train-Acc:0.808\n",
            "I:251 Test-Acc:0.8787 Train-Acc:0.803\n",
            "I:252 Test-Acc:0.8789 Train-Acc:0.812\n",
            "I:253 Test-Acc:0.8792 Train-Acc:0.804\n",
            "I:254 Test-Acc:0.8779 Train-Acc:0.815\n",
            "I:255 Test-Acc:0.8796 Train-Acc:0.811\n",
            "I:256 Test-Acc:0.8798 Train-Acc:0.806\n",
            "I:257 Test-Acc:0.88 Train-Acc:0.803\n",
            "I:258 Test-Acc:0.8776 Train-Acc:0.795\n",
            "I:259 Test-Acc:0.8798 Train-Acc:0.803\n",
            "I:260 Test-Acc:0.8799 Train-Acc:0.805\n",
            "I:261 Test-Acc:0.8789 Train-Acc:0.807\n",
            "I:262 Test-Acc:0.8784 Train-Acc:0.804\n",
            "I:263 Test-Acc:0.8792 Train-Acc:0.806\n",
            "I:264 Test-Acc:0.8777 Train-Acc:0.796\n",
            "I:265 Test-Acc:0.8785 Train-Acc:0.821\n",
            "I:266 Test-Acc:0.8794 Train-Acc:0.81\n",
            "I:267 Test-Acc:0.8783 Train-Acc:0.816\n",
            "I:268 Test-Acc:0.8777 Train-Acc:0.812\n",
            "I:269 Test-Acc:0.8791 Train-Acc:0.812\n",
            "I:270 Test-Acc:0.878 Train-Acc:0.813\n",
            "I:271 Test-Acc:0.8784 Train-Acc:0.82\n",
            "I:272 Test-Acc:0.8792 Train-Acc:0.821\n",
            "I:273 Test-Acc:0.8781 Train-Acc:0.823\n",
            "I:274 Test-Acc:0.8788 Train-Acc:0.816\n",
            "I:275 Test-Acc:0.8793 Train-Acc:0.82\n",
            "I:276 Test-Acc:0.8781 Train-Acc:0.829\n",
            "I:277 Test-Acc:0.8795 Train-Acc:0.809\n",
            "I:278 Test-Acc:0.875 Train-Acc:0.806\n",
            "I:279 Test-Acc:0.8795 Train-Acc:0.813\n",
            "I:280 Test-Acc:0.88 Train-Acc:0.816\n",
            "I:281 Test-Acc:0.8796 Train-Acc:0.819\n",
            "I:282 Test-Acc:0.8802 Train-Acc:0.809\n",
            "I:283 Test-Acc:0.8804 Train-Acc:0.811\n",
            "I:284 Test-Acc:0.8779 Train-Acc:0.808\n",
            "I:285 Test-Acc:0.8816 Train-Acc:0.82\n",
            "I:286 Test-Acc:0.8792 Train-Acc:0.822\n",
            "I:287 Test-Acc:0.8791 Train-Acc:0.817\n",
            "I:288 Test-Acc:0.8769 Train-Acc:0.814\n",
            "I:289 Test-Acc:0.8785 Train-Acc:0.807\n",
            "I:290 Test-Acc:0.8778 Train-Acc:0.817\n",
            "I:291 Test-Acc:0.8794 Train-Acc:0.82\n",
            "I:292 Test-Acc:0.8804 Train-Acc:0.824\n",
            "I:293 Test-Acc:0.8779 Train-Acc:0.812\n",
            "I:294 Test-Acc:0.8784 Train-Acc:0.816\n",
            "I:295 Test-Acc:0.877 Train-Acc:0.817\n",
            "I:296 Test-Acc:0.8767 Train-Acc:0.826\n",
            "I:297 Test-Acc:0.8774 Train-Acc:0.816\n",
            "I:298 Test-Acc:0.8774 Train-Acc:0.804\n",
            "I:299 Test-Acc:0.8774 Train-Acc:0.814"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seQsxl2JN9gd",
        "outputId": "701b20fc-cc03-4006-89b4-f1394be54fb3"
      },
      "source": [
        "import sys\n",
        "\n",
        "f = open('reviews.txt')\n",
        "raw_reviews = f.readlines()\n",
        "f.close()\n",
        "\n",
        "f = open('labels.txt')\n",
        "raw_labels = f.readlines()\n",
        "f.close()\n",
        "\n",
        "tokens = list(map(lambda x: set(x.split(\" \")), raw_reviews)) # unique phrases\n",
        "\n",
        "vocab = set()  # unique words\n",
        "for sent in tokens:\n",
        "    for word in sent:\n",
        "        if(len(word) > 0):\n",
        "            vocab.add(word)\n",
        "vocab = list(vocab)\n",
        "\n",
        "word2index = {}\n",
        "\n",
        "for i, word in enumerate(vocab):\n",
        "    word2index[word] = i    # OneHotEncoding\n",
        "\n",
        "input_dataset = list()\n",
        "\n",
        "for sent in tokens:\n",
        "    sent_indices = list()\n",
        "    for word in sent:\n",
        "        try:\n",
        "            sent_indices.append(word2index[word])\n",
        "        except:\n",
        "            \"\"\n",
        "    input_dataset.append(list(set(sent_indices)))\n",
        "\n",
        "target_dataset = list()     # positive = 1, negative = 0\n",
        "for label in raw_labels:\n",
        "    if label == 'positive\\n':\n",
        "        target_dataset.append(1)\n",
        "    else:\n",
        "        target_dataset.append(0)\n",
        "\n",
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3WkCnMiN9jw",
        "outputId": "d8dd38e6-92a1-402b-d88b-3afb9c8bb7f6"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "alpha, iterations = (0.01, 2)\n",
        "hidden_size = 100\n",
        "\n",
        "weights_0_1 = 0.2 * np.random.random((len(vocab), hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2 * np.random.random((hidden_size, 1)) - 0.1\n",
        "\n",
        "correct, total = (0, 0)\n",
        "\n",
        "for iter in range(iterations):\n",
        "    for i in range(len(input_dataset) - 1000):\n",
        "        x, y = (input_dataset[i], target_dataset[i])\n",
        "        layer_1 = sigmoid(np.sum(weights_0_1[x], axis=0))\n",
        "        layer_2 = sigmoid(np.dot(layer_1, weights_1_2))\n",
        "        \n",
        "        layer_2_delta = layer_2 - y\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\n",
        "        \n",
        "        weights_0_1[x] -= layer_1_delta * alpha\n",
        "        weights_1_2 -= np.outer(layer_1, layer_2_delta) * alpha\n",
        "        \n",
        "        if (np.abs(layer_2_delta) < 0.5):\n",
        "            correct += 1\n",
        "        \n",
        "        total += 1\n",
        "        \n",
        "        if (i % 10 == 9):\n",
        "            progress = f'{i / float(len(input_dataset))}'\n",
        "            sys.stdout.write(f'\\rIter: {iter} Progress {progress[2:4]}.{progress[4:6]}% Training Accuracy: {correct / float(total)}%')\n",
        "    \n",
        "    print()\n",
        "    \n",
        "# correct, total = (0, 0)\n",
        "\n",
        "for i in range(len(input_dataset) - 1000, len(input_dataset)):\n",
        "    \n",
        "    x, y = (input_dataset[i], target_dataset[i])\n",
        "    \n",
        "    layer_1 = sigmoid(np.sum(weights_0_1[x], axis=0))\n",
        "    layer_2 = sigmoid(np.dot(layer_1, weights_1_2))\n",
        "    \n",
        "    if (np.abs(layer_2_delta) < 0.5):\n",
        "        correct += 1\n",
        "        \n",
        "    total += 1\n",
        "\n",
        "print(f'Test Accuracy: {correct / float(total)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0 Progress 95.99% Training Accuracy: 0.8306666666666667%\n",
            "Iter: 1 Progress 95.99% Training Accuracy: 0.8653333333333333%\n",
            "Test Accuracy: 0.8680816326530613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeA8u1UyN9nA"
      },
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "def similar(target='beautiful', common=10):\n",
        "    target_index = word2index[target]\n",
        "    scores = Counter()\n",
        "    for word, index in word2index.items():\n",
        "        raw_difference = weights_0_1[index] - (weights_0_1[target_index])\n",
        "        squared_difference = raw_difference * raw_difference\n",
        "        scores[word] = -math.sqrt(sum(squared_difference))\n",
        "    return scores.most_common(common)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWObwOeAN9rG",
        "outputId": "e3a6411c-9225-446f-d688-54d2472a2fa9"
      },
      "source": [
        "similar('beautiful', 20)\n",
        "# print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('beautiful', -0.0),\n",
              " ('think', -0.7334691272854597),\n",
              " ('subtle', -0.7400260412357343),\n",
              " ('each', -0.7411945706027657),\n",
              " ('job', -0.7446072476301202),\n",
              " ('jack', -0.7483913111496678),\n",
              " ('captures', -0.7536125401368657),\n",
              " ('very', -0.7546485225573424),\n",
              " ('available', -0.7560123105844818),\n",
              " ('impact', -0.7562904696884659),\n",
              " ('thank', -0.7623802608943913),\n",
              " ('unique', -0.7636041978569582),\n",
              " ('flawless', -0.7649589391781192),\n",
              " ('magic', -0.7655343822546246),\n",
              " ('powerful', -0.7672867502220279),\n",
              " ('pleasantly', -0.7764379927310532),\n",
              " ('gritty', -0.7844444662102938),\n",
              " ('friendship', -0.7890382897713614),\n",
              " ('tight', -0.7895175069583455),\n",
              " ('success', -0.7973392911179611)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO7tmlnEN9tr",
        "outputId": "2da431b3-0749-421c-a141-694c2d7cec46"
      },
      "source": [
        "similar('terrible')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrible', -0.0),\n",
              " ('lacks', -0.7611593455373425),\n",
              " ('worse', -0.7980597488048871),\n",
              " ('poor', -0.8125151153216559),\n",
              " ('annoying', -0.8328908146130615),\n",
              " ('disappointing', -0.8340017305239155),\n",
              " ('horrible', -0.8518564376286751),\n",
              " ('avoid', -0.8578680662091412),\n",
              " ('dull', -0.8593957835326148),\n",
              " ('badly', -0.8739309142888094)]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmre8LooN9vx",
        "outputId": "4d71d2c3-558f-460c-8d5a-2aebc3d28f96"
      },
      "source": [
        "import sys,random,math\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "f = open('reviews.txt')\n",
        "raw_reviews = f.readlines()\n",
        "f.close()\n",
        "\n",
        "\n",
        "tokens = list(map(lambda x: (x.split(\" \")), raw_reviews))\n",
        "wordcnt = Counter()\n",
        "for sent in tokens:\n",
        "    for word in sent:\n",
        "        wordcnt[word] -= 1\n",
        "\n",
        "vocab = list(set(map(lambda x: x[0], wordcnt.most_common())))\n",
        "\n",
        "word2index = {}\n",
        "\n",
        "for i,word in enumerate(vocab):\n",
        "    word2index[word]=i\n",
        "\n",
        "concatenated = list()\n",
        "input_dataset = list()\n",
        "\n",
        "for sent in tokens:\n",
        "    sent_indices = list()\n",
        "    for word in sent:\n",
        "        try:\n",
        "            sent_indices.append(word2index[word])\n",
        "            concatenated.append(word2index[word])\n",
        "        except:\n",
        "            \"\"\n",
        "    input_dataset.append(sent_indices)\n",
        "\n",
        "concatenated = np.array(concatenated)\n",
        "\n",
        "random.shuffle(input_dataset)\n",
        "\n",
        "alpha, iterations = (0.05, 2)\n",
        "hidden_size, window, negative = (50, 2, 5)\n",
        "\n",
        "weights_0_1 = (np.random.rand(len(vocab), hidden_size) - 0.5) * 0.2\n",
        "weights_1_2 = np.random.rand(len(vocab), hidden_size) * 0.2\n",
        "\n",
        "layer_2_target = np.zeros(negative + 1)\n",
        "layer_2_target[0] = 1\n",
        "\n",
        "def similar(target='beautiful', common=10):\n",
        "    target_index = word2index[target]\n",
        "    scores = Counter()\n",
        "    for word, index in word2index.items():\n",
        "        raw_difference = weights_0_1[index] - (weights_0_1[target_index])\n",
        "        squared_difference = raw_difference * raw_difference\n",
        "        scores[word] = -math.sqrt(sum(squared_difference))\n",
        "    return scores.most_common(common)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "for rev_i, review in enumerate(input_dataset * iterations):\n",
        "    for target_i in range(len(review)):\n",
        "\n",
        "        target_samples = [review[target_i]] + \\\n",
        "            list(concatenated[(np.random.rand(negative) * \\\n",
        "                               len(concatenated)).astype('int').tolist()])\n",
        "        \n",
        "        left_context = review[max(0, target_i - window):target_i]\n",
        "        right_context = review[ target_i+1:min(len(review), target_i + window)]\n",
        "        \n",
        "        layer_1 = np.mean(weights_0_1[ left_context + right_context ], axis=0)\n",
        "        layer_2 = sigmoid(layer_1.dot(weights_1_2[target_samples].T))\n",
        "        \n",
        "        layer_2_delta = layer_2 - layer_2_target\n",
        "        layer_1_delta = layer_2_delta.dot(weights_1_2[target_samples])\n",
        "        \n",
        "        weights_0_1[left_context + right_context] -= layer_1_delta * alpha\n",
        "        weights_1_2[target_samples] -= np.outer(layer_2_delta, layer_1)*alpha\n",
        "    if(rev_i % 250 == 0):\n",
        "        sys.stdout.write('\\rProgress:'+str(rev_i/float(len(input_dataset) * iterations)) + \" \" + str(similar('terrible')))\n",
        "        sys.stdout.write('\\rProgress:'+str(rev_i/float(len(input_dataset) * iterations)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress:0.995"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioQk9aEcN9x0",
        "outputId": "f95dcb5e-5897-4d21-cfef-615f6dd50b86"
      },
      "source": [
        "similar('terrible')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrible', -0.0),\n",
              " ('horrible', -2.9276115556585234),\n",
              " ('brilliant', -3.557672506738104),\n",
              " ('pathetic', -3.842699283336314),\n",
              " ('superb', -3.8878675041557145),\n",
              " ('marvelous', -3.9179095240408346),\n",
              " ('masterful', -4.044717447566964),\n",
              " ('phenomenal', -4.09455875937242),\n",
              " ('bad', -4.132111976951308),\n",
              " ('miserable', -4.241021302064761)]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcppUb9mcqOY"
      },
      "source": [
        "def analogy(positive=['terrible','good'],negative=['bad']):\n",
        "    norms = np.sum(weights_0_1 * weights_0_1, axis=1)\n",
        "    norms.resize(norms.shape[0], 1)\n",
        "\n",
        "    normed_weights = weights_0_1 * norms\n",
        "    query_vect = np.zeros(len(weights_0_1[0]))\n",
        "\n",
        "    for word in positive:\n",
        "        query_vect += normed_weights[word2index[word]]\n",
        "    for word in negative:\n",
        "        query_vect -= normed_weights[word2index[word]]\n",
        "    \n",
        "    scores = Counter()\n",
        "    for word, index in word2index.items():\n",
        "        raw_difference = weights_0_1[index] - query_vect\n",
        "        squared_difference = raw_difference * raw_difference\n",
        "        scores[word] = -math.sqrt(sum(squared_difference))\n",
        "    return scores.most_common(10)[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6c7BjEEcqRY",
        "outputId": "e309ff65-7cbd-41d3-df60-e8aa28e49c4a"
      },
      "source": [
        "# terrible - bad + good\n",
        "analogy(['terrible', 'good'], ['bad'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('superb', -220.29245071250298),\n",
              " ('decent', -220.56887762744014),\n",
              " ('terrific', -220.690346314643),\n",
              " ('fine', -220.77596193617697),\n",
              " ('worth', -220.93298505790284),\n",
              " ('nice', -221.02128969514885),\n",
              " ('terrible', -221.05216641316423),\n",
              " ('perfect', -221.06149411253153),\n",
              " ('great', -221.18919679123678)]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yau5zqWncqTm",
        "outputId": "aaa2ec69-8944-497a-c7c0-44e83d9b4626"
      },
      "source": [
        "# elizabeth - she + he\n",
        "analogy(['elizabeth','he'], ['she'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('peter', -177.09655223197822),\n",
              " ('david', -177.2301855087902),\n",
              " ('christopher', -177.39930774607205),\n",
              " ('tom', -177.49595316648265),\n",
              " ('richard', -177.52260913357009),\n",
              " ('john', -177.54166224621156),\n",
              " ('fred', -177.59428672434404),\n",
              " ('de', -177.62210555415427),\n",
              " ('von', -177.6800624779045)]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1ub3OqCenBU",
        "outputId": "019cd07f-ff56-43c7-90eb-df514b8c68e3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "norms = np.sum(weights_0_1 * weights_0_1, axis=1)\n",
        "norms.resize(norms.shape[0], 1)\n",
        "normed_weights = weights_0_1 * norms\n",
        "\n",
        "def make_sent_vect(words):\n",
        "    indices = list(map(lambda x:word2index[x], filter(lambda x:x in word2index,words)))\n",
        "    return np.mean(normed_weights[indices],axis=0)\n",
        "\n",
        "reviews2vectors = list()\n",
        "for review in tokens:\n",
        "    reviews2vectors.append(make_sent_vect(review))\n",
        "\n",
        "reviews2vectors = np.array(reviews2vectors)\n",
        "\n",
        "def most_similar_reviews(review):\n",
        "    v = make_sent_vect(review)\n",
        "    scores = Counter()\n",
        "    for i, val in enumerate(reviews2vectors.dot(v)):\n",
        "        scores[i] = val\n",
        "    \n",
        "    most_similar = list()\n",
        "    for idx, score in scores.most_common(3):\n",
        "        most_similar.append(raw_reviews[idx][0:40])\n",
        "    return most_similar\n",
        "\n",
        "most_similar_reviews(['boring','awful'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i  m surprised how many people give this',\n",
              " 'probably new zealands worst movie ever m',\n",
              " 'clearly an hilarious movie .  br    br  ']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRoMrocyenGp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0J1ys0kenTE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}